Requirements:
- 10 to 15 pages with pictures
- runnable code

Exercise:
- 4 datasets as input
- 3 classifier algorithms per dataset

Task1:
- Data import, exploration and preprocessing
  (fulfill all requirements from ex0 feedback)

Task2:
- Run classifiers, change parameters

Task3:
design evaluation, mainly by varying single parameters at once
- check performance, primary effectiveness, also efficiency
- choose performance measures
- list best classifiers
- how is the performace changing when we change preprocessing strat
- identify differences in datasets(e.g. missing vals) and analyze performance of algos
- significance testing for at least one baseline (only if results are comparable)
- perform experiments for holdout and cross validation

Task4: 
write report



Validation types:
1 Cross validation:
  split data in k pieces and do train and testsplit on all k pieces
  measure performance of algorithm on all pieces (mean std,...)
2 Holdout validation
  split whole dataset in test ad train set
  measure performance of algoritm 

Main peformance metrics:
1 Confusion matrix:
  [[true negative, false negative], [false positive, true positive]]
2 percision: 
  TP/(TP+FP)
3 recall:
  TP/(TP+FN)
Use 2+3 together for a good metric
4 F1 (Harmonic mean), 1 if percission and recall are both high, <1/2 if one of them is low:
  2/(1/percision + 1/recall)
5 Accuracy:
  (TP+TN)/#samples
5 ROC curve:
  plot recall over percission

Effectiveness: performance measures like accuracy percision,...
Efficiency: time to train, predict,...



