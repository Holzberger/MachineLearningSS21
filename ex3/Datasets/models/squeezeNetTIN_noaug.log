epoch,accuracy,loss,val_accuracy,val_loss
0,0.013144444674253464,5.134871482849121,0.027000000700354576,4.947420120239258
1,0.03881110996007919,4.7944254875183105,0.06260000169277191,4.58000373840332
2,0.06913333386182785,4.503287315368652,0.09109999984502792,4.342695713043213
3,0.09441111236810684,4.2929887771606445,0.11169999837875366,4.1941728591918945
4,0.1172555536031723,4.125385761260986,0.13369999825954437,4.036542892456055
5,0.13757777214050293,3.988023519515991,0.14319999516010284,3.951144218444824
6,0.1559777706861496,3.872084379196167,0.1623000055551529,3.8433334827423096
7,0.17069999873638153,3.768878936767578,0.16519999504089355,3.8206491470336914
8,0.1851000040769577,3.6764135360717773,0.18490000069141388,3.6950483322143555
9,0.1986333280801773,3.5892539024353027,0.1891999989748001,3.6283488273620605
10,0.2141222208738327,3.507146120071411,0.19290000200271606,3.666503429412842
11,0.22744444012641907,3.432126998901367,0.20409999787807465,3.579422950744629
12,0.2377111166715622,3.357806921005249,0.2110999971628189,3.535794973373413
13,0.24862222373485565,3.294651746749878,0.22830000519752502,3.431380033493042
14,0.26030001044273376,3.233349323272705,0.2387000024318695,3.3802566528320312
15,0.27186667919158936,3.1668853759765625,0.23909999430179596,3.393444061279297
16,0.282966673374176,3.111177444458008,0.2475000023841858,3.348790168762207
17,0.29161110520362854,3.0581583976745605,0.2524999976158142,3.314601182937622
18,0.30131110548973083,3.000598907470703,0.2567000091075897,3.2714154720306396
19,0.3100889027118683,2.948850393295288,0.26350000500679016,3.309568405151367
20,0.31888890266418457,2.8969485759735107,0.2703999876976013,3.2195818424224854
21,0.32846665382385254,2.847114324569702,0.2685999870300293,3.231431484222412
22,0.3374222218990326,2.798229932785034,0.2775000035762787,3.200024127960205
23,0.3452000021934509,2.7520246505737305,0.2720000147819519,3.2309694290161133
24,0.3544333279132843,2.7021915912628174,0.27869999408721924,3.206076145172119
25,0.36469998955726624,2.656160593032837,0.2590999901294708,3.2822136878967285
26,0.37201112508773804,2.6106951236724854,0.2847000062465668,3.180996894836426
27,0.3814333379268646,2.5643997192382812,0.26910001039505005,3.3274807929992676
28,0.3899777829647064,2.518167495727539,0.28519999980926514,3.1804258823394775
29,0.39711111783981323,2.4748268127441406,0.290800005197525,3.1757254600524902
30,0.4032222330570221,2.440453290939331,0.2912999987602234,3.1777255535125732
31,0.41457778215408325,2.3833107948303223,0.29170000553131104,3.2016639709472656
32,0.4219111204147339,2.3468892574310303,0.28790000081062317,3.205516815185547
33,0.42952221632003784,2.3027851581573486,0.2831000089645386,3.2673497200012207
34,0.4381222128868103,2.265387773513794,0.2937000095844269,3.2356860637664795
35,0.49871110916137695,1.9859164953231812,0.3059000074863434,3.2024896144866943
36,0.5061110854148865,1.949746012687683,0.3066999912261963,3.1962733268737793
37,0.5099889039993286,1.9318723678588867,0.30559998750686646,3.2047202587127686
38,0.5129333138465881,1.922256588935852,0.30640000104904175,3.230877637863159
39,0.5143666863441467,1.9095531702041626,0.3050999939441681,3.219683885574341
40,0.5224778056144714,1.8755565881729126,0.30640000104904175,3.2338857650756836
41,0.5245110988616943,1.8688853979110718,0.30630001425743103,3.238103151321411
42,0.5250555276870728,1.8663890361785889,0.3034000098705292,3.2396445274353027
43,0.5252222418785095,1.866307258605957,0.3043000102043152,3.2418065071105957
44,0.5261111259460449,1.8612548112869263,0.3050000071525574,3.2370941638946533
45,0.5277222394943237,1.8601515293121338,0.30559998750686646,3.2400643825531006
46,0.52602219581604,1.8587572574615479,0.30559998750686646,3.2403359413146973
47,0.5261222124099731,1.861444115638733,0.3057999908924103,3.2399306297302246
48,0.5276888608932495,1.8615355491638184,0.3059000074863434,3.2395408153533936
49,0.5256333351135254,1.8610326051712036,0.305400013923645,3.2408792972564697
50,0.5258222222328186,1.8593041896820068,0.305400013923645,3.240767240524292
51,0.5266110897064209,1.8579093217849731,0.3052999973297119,3.240670919418335
52,0.5260444283485413,1.8612223863601685,0.30550000071525574,3.240605354309082
53,0.5270333290100098,1.8561334609985352,0.3050999939441681,3.240628242492676
54,0.5244110822677612,1.8619836568832397,0.3050999939441681,3.2405786514282227

Epoch 1/150
1407/1407 [==============================] - 49s 32ms/step - loss: 5.1349 - accuracy: 0.0131 - val_loss: 4.9474 - val_accuracy: 0.0270
Epoch 2/150
1407/1407 [==============================] - 44s 31ms/step - loss: 4.7944 - accuracy: 0.0388 - val_loss: 4.5800 - val_accuracy: 0.0626
Epoch 3/150
1407/1407 [==============================] - 45s 32ms/step - loss: 4.5033 - accuracy: 0.0691 - val_loss: 4.3427 - val_accuracy: 0.0911
Epoch 4/150
1407/1407 [==============================] - 44s 31ms/step - loss: 4.2930 - accuracy: 0.0944 - val_loss: 4.1942 - val_accuracy: 0.1117
Epoch 5/150
1407/1407 [==============================] - 45s 32ms/step - loss: 4.1254 - accuracy: 0.1173 - val_loss: 4.0365 - val_accuracy: 0.1337
Epoch 6/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.9880 - accuracy: 0.1376 - val_loss: 3.9511 - val_accuracy: 0.1432
Epoch 7/150
1407/1407 [==============================] - 44s 31ms/step - loss: 3.8721 - accuracy: 0.1560 - val_loss: 3.8433 - val_accuracy: 0.1623
Epoch 8/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.7689 - accuracy: 0.1707 - val_loss: 3.8206 - val_accuracy: 0.1652
Epoch 9/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.6764 - accuracy: 0.1851 - val_loss: 3.6950 - val_accuracy: 0.1849
Epoch 10/150
1407/1407 [==============================] - 44s 31ms/step - loss: 3.5893 - accuracy: 0.1986 - val_loss: 3.6283 - val_accuracy: 0.1892
Epoch 11/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.5071 - accuracy: 0.2141 - val_loss: 3.6665 - val_accuracy: 0.1929
Epoch 12/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.4321 - accuracy: 0.2274 - val_loss: 3.5794 - val_accuracy: 0.2041
Epoch 13/150
1407/1407 [==============================] - 46s 33ms/step - loss: 3.3578 - accuracy: 0.2377 - val_loss: 3.5358 - val_accuracy: 0.2111
Epoch 14/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.2947 - accuracy: 0.2486 - val_loss: 3.4314 - val_accuracy: 0.2283
Epoch 15/150
1407/1407 [==============================] - 44s 31ms/step - loss: 3.2333 - accuracy: 0.2603 - val_loss: 3.3803 - val_accuracy: 0.2387
Epoch 16/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.1669 - accuracy: 0.2719 - val_loss: 3.3934 - val_accuracy: 0.2391
Epoch 17/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.1112 - accuracy: 0.2830 - val_loss: 3.3488 - val_accuracy: 0.2475
Epoch 18/150
1407/1407 [==============================] - 45s 32ms/step - loss: 3.0582 - accuracy: 0.2916 - val_loss: 3.3146 - val_accuracy: 0.2525
Epoch 19/150
1407/1407 [==============================] - 44s 31ms/step - loss: 3.0006 - accuracy: 0.3013 - val_loss: 3.2714 - val_accuracy: 0.2567
Epoch 20/150
1407/1407 [==============================] - 44s 31ms/step - loss: 2.9489 - accuracy: 0.3101 - val_loss: 3.3096 - val_accuracy: 0.2635
Epoch 21/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.8969 - accuracy: 0.3189 - val_loss: 3.2196 - val_accuracy: 0.2704
Epoch 22/150
1407/1407 [==============================] - 44s 31ms/step - loss: 2.8471 - accuracy: 0.3285 - val_loss: 3.2314 - val_accuracy: 0.2686
Epoch 23/150
1407/1407 [==============================] - 44s 32ms/step - loss: 2.7982 - accuracy: 0.3374 - val_loss: 3.2000 - val_accuracy: 0.2775
Epoch 24/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.7520 - accuracy: 0.3452 - val_loss: 3.2310 - val_accuracy: 0.2720
Epoch 25/150
1407/1407 [==============================] - 44s 31ms/step - loss: 2.7022 - accuracy: 0.3544 - val_loss: 3.2061 - val_accuracy: 0.2787
Epoch 26/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.6562 - accuracy: 0.3647 - val_loss: 3.2822 - val_accuracy: 0.2591
Epoch 27/150
1407/1407 [==============================] - 44s 31ms/step - loss: 2.6107 - accuracy: 0.3720 - val_loss: 3.1810 - val_accuracy: 0.2847
Epoch 28/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.5644 - accuracy: 0.3814 - val_loss: 3.3275 - val_accuracy: 0.2691
Epoch 29/150
1407/1407 [==============================] - 46s 33ms/step - loss: 2.5182 - accuracy: 0.3900 - val_loss: 3.1804 - val_accuracy: 0.2852
Epoch 30/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.4748 - accuracy: 0.3971 - val_loss: 3.1757 - val_accuracy: 0.2908
Epoch 31/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.4405 - accuracy: 0.4032 - val_loss: 3.1777 - val_accuracy: 0.2913
Epoch 32/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.3833 - accuracy: 0.4146 - val_loss: 3.2017 - val_accuracy: 0.2917
Epoch 33/150
1407/1407 [==============================] - 44s 32ms/step - loss: 2.3469 - accuracy: 0.4219 - val_loss: 3.2055 - val_accuracy: 0.2879
Epoch 34/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.3028 - accuracy: 0.4295 - val_loss: 3.2673 - val_accuracy: 0.2831
Epoch 35/150
1407/1407 [==============================] - 45s 32ms/step - loss: 2.2654 - accuracy: 0.4381 - val_loss: 3.2357 - val_accuracy: 0.2937

Epoch 00035: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 36/150
1407/1407 [==============================] - 44s 31ms/step - loss: 1.9859 - accuracy: 0.4987 - val_loss: 3.2025 - val_accuracy: 0.3059
Epoch 37/150
1407/1407 [==============================] - 44s 32ms/step - loss: 1.9497 - accuracy: 0.5061 - val_loss: 3.1963 - val_accuracy: 0.3067
Epoch 38/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.9319 - accuracy: 0.5100 - val_loss: 3.2047 - val_accuracy: 0.3056
Epoch 39/150
1407/1407 [==============================] - 44s 32ms/step - loss: 1.9223 - accuracy: 0.5129 - val_loss: 3.2309 - val_accuracy: 0.3064
Epoch 40/150
1407/1407 [==============================] - 46s 33ms/step - loss: 1.9096 - accuracy: 0.5144 - val_loss: 3.2197 - val_accuracy: 0.3051

Epoch 00040: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 41/150
1407/1407 [==============================] - 44s 31ms/step - loss: 1.8756 - accuracy: 0.5225 - val_loss: 3.2339 - val_accuracy: 0.3064
Epoch 42/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8689 - accuracy: 0.5245 - val_loss: 3.2381 - val_accuracy: 0.3063
Epoch 43/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8664 - accuracy: 0.5251 - val_loss: 3.2396 - val_accuracy: 0.3034
Epoch 44/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8663 - accuracy: 0.5252 - val_loss: 3.2418 - val_accuracy: 0.3043
Epoch 45/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8613 - accuracy: 0.5261 - val_loss: 3.2371 - val_accuracy: 0.3050

Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 46/150
1407/1407 [==============================] - 46s 33ms/step - loss: 1.8602 - accuracy: 0.5277 - val_loss: 3.2401 - val_accuracy: 0.3056
Epoch 47/150
1407/1407 [==============================] - 46s 32ms/step - loss: 1.8588 - accuracy: 0.5260 - val_loss: 3.2403 - val_accuracy: 0.3056
Epoch 48/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8614 - accuracy: 0.5261 - val_loss: 3.2399 - val_accuracy: 0.3058
Epoch 49/150
1407/1407 [==============================] - 44s 32ms/step - loss: 1.8615 - accuracy: 0.5277 - val_loss: 3.2395 - val_accuracy: 0.3059
Epoch 50/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8610 - accuracy: 0.5256 - val_loss: 3.2409 - val_accuracy: 0.3054

Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 51/150
1407/1407 [==============================] - 46s 32ms/step - loss: 1.8593 - accuracy: 0.5258 - val_loss: 3.2408 - val_accuracy: 0.3054
Epoch 52/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8579 - accuracy: 0.5266 - val_loss: 3.2407 - val_accuracy: 0.3053
Epoch 53/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8612 - accuracy: 0.5260 - val_loss: 3.2406 - val_accuracy: 0.3055
Epoch 54/150
1407/1407 [==============================] - 46s 32ms/step - loss: 1.8561 - accuracy: 0.5270 - val_loss: 3.2406 - val_accuracy: 0.3051
Epoch 55/150
1407/1407 [==============================] - 45s 32ms/step - loss: 1.8620 - accuracy: 0.5244 - val_loss: 3.2406 - val_accuracy: 0.3051

Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
