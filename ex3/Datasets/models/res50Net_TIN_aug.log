epoch,accuracy,loss,val_accuracy,val_loss
0,0.012466666288673878,5.429961681365967,0.08449999988079071,4.74885368347168
1,0.038144443184137344,4.846237659454346,0.12809999287128448,4.123067855834961
2,0.06465555727481842,4.450173854827881,0.16660000383853912,3.795745372772217
3,0.0866222232580185,4.233851909637451,0.18469999730587006,3.6466586589813232
4,0.10332222282886505,4.0877838134765625,0.2053000032901764,3.533428192138672
5,0.11856666952371597,3.97525691986084,0.21729999780654907,3.4410359859466553
6,0.13277778029441833,3.887864828109741,0.227400004863739,3.3685383796691895
7,0.14429999887943268,3.815599203109741,0.23639999330043793,3.30588436126709
8,0.15413333475589752,3.758174419403076,0.24940000474452972,3.2615978717803955
9,0.16670000553131104,3.6964478492736816,0.25459998846054077,3.217008590698242
10,0.17419999837875366,3.6555933952331543,0.26269999146461487,3.199765920639038
11,0.18138888478279114,3.613250970840454,0.2711000144481659,3.1546521186828613
12,0.18805555999279022,3.573228120803833,0.2694999873638153,3.150613307952881
13,0.19539999961853027,3.5424535274505615,0.2750999927520752,3.11195969581604
14,0.20047777891159058,3.507193088531494,0.2793999910354614,3.0954558849334717
15,0.20648889243602753,3.4883031845092773,0.28540000319480896,3.075033664703369
16,0.2102888822555542,3.4667320251464844,0.2897999882698059,3.0682625770568848
17,0.2140222191810608,3.441077709197998,0.2971000075340271,3.034642457962036
18,0.22190000116825104,3.4153850078582764,0.29829999804496765,3.0263619422912598
19,0.2249000072479248,3.3994016647338867,0.2980000078678131,3.0047309398651123
20,0.22677777707576752,3.3825836181640625,0.30070000886917114,3.0177881717681885
21,0.2307777851819992,3.3597500324249268,0.3052999973297119,2.992318868637085
22,0.23447777330875397,3.342298984527588,0.30809998512268066,2.987105369567871
23,0.2393111139535904,3.336686372756958,0.31130000948905945,2.9746525287628174
24,0.23826666176319122,3.3255820274353027,0.30979999899864197,2.9727184772491455
25,0.24415555596351624,3.3069183826446533,0.3158999979496002,2.9557085037231445
26,0.24476666748523712,3.2936244010925293,0.3133000135421753,2.950260877609253
27,0.24627777934074402,3.2837328910827637,0.3167000114917755,2.933006525039673
28,0.2502555549144745,3.2711098194122314,0.3197000026702881,2.920358896255493
29,0.2535666525363922,3.2547125816345215,0.3208000063896179,2.9224143028259277
30,0.2538333237171173,3.2435052394866943,0.32409998774528503,2.9183149337768555
31,0.25673332810401917,3.233943462371826,0.3280999958515167,2.905702829360962
32,0.2596110999584198,3.222954750061035,0.3248000144958496,2.9148447513580322
33,0.263355553150177,3.2169132232666016,0.3228999972343445,2.9258525371551514
34,0.2603444457054138,3.2073349952697754,0.32589998841285706,2.89076828956604
35,0.2649777829647064,3.1922528743743896,0.32899999618530273,2.902193546295166
36,0.26653334498405457,3.1871163845062256,0.3257000148296356,2.902712106704712
37,0.2696888744831085,3.1808600425720215,0.32899999618530273,2.88757061958313
38,0.27168887853622437,3.167933940887451,0.32260000705718994,2.9006617069244385
39,0.27486667037010193,3.1580698490142822,0.3310000002384186,2.889615058898926
40,0.27185556292533875,3.1546432971954346,0.3296000063419342,2.881803035736084
41,0.2762777805328369,3.144340991973877,0.3271999955177307,2.886690139770508
42,0.2765333354473114,3.1356799602508545,0.3262999951839447,2.8847131729125977
43,0.2801111042499542,3.1289429664611816,0.3303999900817871,2.869259834289551
44,0.2808111011981964,3.1191346645355225,0.33149999380111694,2.878671169281006
45,0.28145554661750793,3.115534782409668,0.3310999870300293,2.870466947555542
46,0.2819777727127075,3.11208438873291,0.3345000147819519,2.885688543319702
47,0.2829444408416748,3.1008858680725098,0.33489999175071716,2.861785411834717
48,0.2853333353996277,3.0926239490509033,0.3424000144004822,2.8432629108428955
49,0.287200003862381,3.089470863342285,0.33660000562667847,2.8707313537597656
50,0.2876666784286499,3.073324680328369,0.3361000120639801,2.866199493408203
51,0.28985556960105896,3.0708436965942383,0.34139999747276306,2.8513543605804443
52,0.29036667943000793,3.067460298538208,0.3379000127315521,2.857945680618286
53,0.2903333306312561,3.0656025409698486,0.34369999170303345,2.8325631618499756
54,0.29127776622772217,3.0625343322753906,0.34380000829696655,2.8377938270568848
55,0.2958555519580841,3.054581642150879,0.3382999897003174,2.8524084091186523
56,0.2955666780471802,3.0451290607452393,0.34139999747276306,2.8626558780670166
57,0.29738888144493103,3.033336877822876,0.3407000005245209,2.851318836212158
58,0.2979111075401306,3.035489559173584,0.3433000147342682,2.8373477458953857
59,0.302011102437973,3.0036544799804688,0.3479999899864197,2.8184854984283447
60,0.3046444356441498,2.9936063289642334,0.34779998660087585,2.8251867294311523
61,0.30656665563583374,2.987729072570801,0.3517000079154968,2.810030460357666
62,0.3067333400249481,2.9818191528320312,0.34389999508857727,2.8146469593048096
63,0.3111555576324463,2.974069833755493,0.34850001335144043,2.8104724884033203
64,0.30871111154556274,2.9681694507598877,0.35269999504089355,2.809295892715454
65,0.30953332781791687,2.965209722518921,0.3490000069141388,2.832392930984497
66,0.3106444478034973,2.9683010578155518,0.3474000096321106,2.807176351547241
67,0.3111666738986969,2.9579451084136963,0.3443000018596649,2.8280069828033447
68,0.310922235250473,2.957500696182251,0.34549999237060547,2.8141894340515137
69,0.31208887696266174,2.953507661819458,0.35409998893737793,2.7979376316070557
70,0.3157222270965576,2.9494810104370117,0.35010001063346863,2.805074453353882
71,0.31315556168556213,2.9459357261657715,0.35089999437332153,2.8100428581237793
72,0.3132888972759247,2.9423489570617676,0.3529999852180481,2.8046982288360596
73,0.31404444575309753,2.9414222240448,0.34850001335144043,2.809335231781006
74,0.31645554304122925,2.9433603286743164,0.3513999879360199,2.821197748184204
75,0.31432223320007324,2.940981864929199,0.3476000130176544,2.826301336288452
76,0.31654444336891174,2.935999631881714,0.3522999882698059,2.8172740936279297
77,0.31672221422195435,2.9325673580169678,0.3540000021457672,2.793602228164673
78,0.31878888607025146,2.9314000606536865,0.35120001435279846,2.8201284408569336
79,0.31566667556762695,2.9405198097229004,0.34779998660087585,2.8233680725097656
80,0.3141222298145294,2.933345079421997,0.35030001401901245,2.8169755935668945
81,0.31448888778686523,2.939074993133545,0.3447999954223633,2.816110849380493
82,0.3157333433628082,2.937004804611206,0.349700003862381,2.8001909255981445
83,0.3149222135543823,2.9352943897247314,0.3513999879360199,2.819551467895508
84,0.31529998779296875,2.9338836669921875,0.35370001196861267,2.812014102935791
85,0.31575554609298706,2.929220199584961,0.3513000011444092,2.808234453201294
86,0.31354445219039917,2.9427947998046875,0.3499000072479248,2.820547103881836
87,0.3182666599750519,2.928380250930786,0.35280001163482666,2.8226606845855713
88,0.31662222743034363,2.936673164367676,0.35100001096725464,2.7996954917907715
89,0.31796666979789734,2.933710813522339,0.35260000824928284,2.814331531524658
90,0.3157333433628082,2.9373395442962646,0.34610000252723694,2.8235723972320557
91,0.3165222108364105,2.9388020038604736,0.3474999964237213,2.8166372776031494
92,0.31541112065315247,2.937129259109497,0.35030001401901245,2.802626371383667


Epoch 1/150
2813/2813 [==============================] - 193s 67ms/step - loss: 5.6025 - accuracy: 0.0079 - val_loss: 4.7489 - val_accuracy: 0.0845
Epoch 2/150
2813/2813 [==============================] - 173s 62ms/step - loss: 4.9810 - accuracy: 0.0311 - val_loss: 4.1231 - val_accuracy: 0.1281
Epoch 3/150
2813/2813 [==============================] - 180s 64ms/step - loss: 4.5163 - accuracy: 0.0588 - val_loss: 3.7957 - val_accuracy: 0.1666
Epoch 4/150
2813/2813 [==============================] - 175s 62ms/step - loss: 4.2668 - accuracy: 0.0838 - val_loss: 3.6467 - val_accuracy: 0.1847
Epoch 5/150
2813/2813 [==============================] - 178s 63ms/step - loss: 4.1106 - accuracy: 0.0991 - val_loss: 3.5334 - val_accuracy: 0.2053
Epoch 6/150
2813/2813 [==============================] - 180s 64ms/step - loss: 3.9957 - accuracy: 0.1149 - val_loss: 3.4410 - val_accuracy: 0.2173
Epoch 7/150
2813/2813 [==============================] - 173s 62ms/step - loss: 3.9063 - accuracy: 0.1296 - val_loss: 3.3685 - val_accuracy: 0.2274
Epoch 8/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.8311 - accuracy: 0.1395 - val_loss: 3.3059 - val_accuracy: 0.2364
Epoch 9/150
2813/2813 [==============================] - 173s 61ms/step - loss: 3.7574 - accuracy: 0.1525 - val_loss: 3.2616 - val_accuracy: 0.2494
Epoch 10/150
2813/2813 [==============================] - 173s 62ms/step - loss: 3.7060 - accuracy: 0.1658 - val_loss: 3.2170 - val_accuracy: 0.2546
Epoch 11/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.6546 - accuracy: 0.1732 - val_loss: 3.1998 - val_accuracy: 0.2627
Epoch 12/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.6233 - accuracy: 0.1783 - val_loss: 3.1547 - val_accuracy: 0.2711
Epoch 13/150
2813/2813 [==============================] - 170s 60ms/step - loss: 3.5825 - accuracy: 0.1887 - val_loss: 3.1506 - val_accuracy: 0.2695
Epoch 14/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.5374 - accuracy: 0.1946 - val_loss: 3.1120 - val_accuracy: 0.2751
Epoch 15/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.5096 - accuracy: 0.1990 - val_loss: 3.0955 - val_accuracy: 0.2794
Epoch 16/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.4870 - accuracy: 0.2057 - val_loss: 3.0750 - val_accuracy: 0.2854
Epoch 17/150
2813/2813 [==============================] - 173s 61ms/step - loss: 3.4684 - accuracy: 0.2099 - val_loss: 3.0683 - val_accuracy: 0.2898
Epoch 18/150
2813/2813 [==============================] - 173s 62ms/step - loss: 3.4373 - accuracy: 0.2141 - val_loss: 3.0346 - val_accuracy: 0.2971
Epoch 19/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.4112 - accuracy: 0.2212 - val_loss: 3.0264 - val_accuracy: 0.2983
Epoch 20/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.3922 - accuracy: 0.2263 - val_loss: 3.0047 - val_accuracy: 0.2980
Epoch 21/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.3789 - accuracy: 0.2275 - val_loss: 3.0178 - val_accuracy: 0.3007
Epoch 22/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.3632 - accuracy: 0.2298 - val_loss: 2.9923 - val_accuracy: 0.3053
Epoch 23/150
2813/2813 [==============================] - 173s 62ms/step - loss: 3.3308 - accuracy: 0.2333 - val_loss: 2.9871 - val_accuracy: 0.3081
Epoch 24/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.3319 - accuracy: 0.2388 - val_loss: 2.9747 - val_accuracy: 0.3113
Epoch 25/150
2813/2813 [==============================] - 173s 61ms/step - loss: 3.3238 - accuracy: 0.2392 - val_loss: 2.9727 - val_accuracy: 0.3098
Epoch 26/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.3002 - accuracy: 0.2455 - val_loss: 2.9557 - val_accuracy: 0.3159
Epoch 27/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.2855 - accuracy: 0.2466 - val_loss: 2.9503 - val_accuracy: 0.3133
Epoch 28/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.2788 - accuracy: 0.2478 - val_loss: 2.9330 - val_accuracy: 0.3167
Epoch 29/150
2813/2813 [==============================] - 173s 61ms/step - loss: 3.2616 - accuracy: 0.2505 - val_loss: 2.9204 - val_accuracy: 0.3197
Epoch 30/150
2813/2813 [==============================] - 170s 60ms/step - loss: 3.2577 - accuracy: 0.2551 - val_loss: 2.9224 - val_accuracy: 0.3208
Epoch 31/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.2409 - accuracy: 0.2548 - val_loss: 2.9183 - val_accuracy: 0.3241
Epoch 32/150
2813/2813 [==============================] - 173s 62ms/step - loss: 3.2317 - accuracy: 0.2570 - val_loss: 2.9057 - val_accuracy: 0.3281
Epoch 33/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.2123 - accuracy: 0.2624 - val_loss: 2.9148 - val_accuracy: 0.3248
Epoch 34/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.2043 - accuracy: 0.2643 - val_loss: 2.9259 - val_accuracy: 0.3229
Epoch 35/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.2018 - accuracy: 0.2604 - val_loss: 2.8908 - val_accuracy: 0.3259
Epoch 36/150
2813/2813 [==============================] - 170s 60ms/step - loss: 3.1789 - accuracy: 0.2658 - val_loss: 2.9022 - val_accuracy: 0.3290
Epoch 37/150
2813/2813 [==============================] - 173s 62ms/step - loss: 3.1852 - accuracy: 0.2658 - val_loss: 2.9027 - val_accuracy: 0.3257
Epoch 38/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.1760 - accuracy: 0.2691 - val_loss: 2.8876 - val_accuracy: 0.3290
Epoch 39/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.1642 - accuracy: 0.2729 - val_loss: 2.9007 - val_accuracy: 0.3226
Epoch 40/150
2813/2813 [==============================] - 173s 61ms/step - loss: 3.1557 - accuracy: 0.2752 - val_loss: 2.8896 - val_accuracy: 0.3310
Epoch 41/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.1449 - accuracy: 0.2758 - val_loss: 2.8818 - val_accuracy: 0.3296
Epoch 42/150
2813/2813 [==============================] - 169s 60ms/step - loss: 3.1285 - accuracy: 0.2788 - val_loss: 2.8867 - val_accuracy: 0.3272
Epoch 43/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.1179 - accuracy: 0.2783 - val_loss: 2.8847 - val_accuracy: 0.3263
Epoch 44/150
2813/2813 [==============================] - 173s 61ms/step - loss: 3.1178 - accuracy: 0.2817 - val_loss: 2.8693 - val_accuracy: 0.3304
Epoch 45/150
2813/2813 [==============================] - 169s 60ms/step - loss: 3.1047 - accuracy: 0.2836 - val_loss: 2.8787 - val_accuracy: 0.3315
Epoch 46/150
2813/2813 [==============================] - 173s 61ms/step - loss: 3.1190 - accuracy: 0.2807 - val_loss: 2.8705 - val_accuracy: 0.3311
Epoch 47/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.1118 - accuracy: 0.2817 - val_loss: 2.8857 - val_accuracy: 0.3345
Epoch 48/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.0977 - accuracy: 0.2823 - val_loss: 2.8618 - val_accuracy: 0.3349
Epoch 49/150
2813/2813 [==============================] - 169s 60ms/step - loss: 3.0811 - accuracy: 0.2876 - val_loss: 2.8433 - val_accuracy: 0.3424
Epoch 50/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.0894 - accuracy: 0.2869 - val_loss: 2.8707 - val_accuracy: 0.3366
Epoch 51/150
2813/2813 [==============================] - 168s 60ms/step - loss: 3.0586 - accuracy: 0.2901 - val_loss: 2.8662 - val_accuracy: 0.3361
Epoch 52/150
2813/2813 [==============================] - 175s 62ms/step - loss: 3.0642 - accuracy: 0.2900 - val_loss: 2.8514 - val_accuracy: 0.3414
Epoch 53/150
2813/2813 [==============================] - 172s 61ms/step - loss: 3.0568 - accuracy: 0.2927 - val_loss: 2.8579 - val_accuracy: 0.3379
Epoch 54/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.0508 - accuracy: 0.2927 - val_loss: 2.8326 - val_accuracy: 0.3437
Epoch 55/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.0543 - accuracy: 0.2920 - val_loss: 2.8378 - val_accuracy: 0.3438
Epoch 56/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.0506 - accuracy: 0.2971 - val_loss: 2.8524 - val_accuracy: 0.3383
Epoch 57/150
2813/2813 [==============================] - 178s 63ms/step - loss: 3.0450 - accuracy: 0.2950 - val_loss: 2.8627 - val_accuracy: 0.3414
Epoch 58/150
2813/2813 [==============================] - 174s 62ms/step - loss: 3.0273 - accuracy: 0.2990 - val_loss: 2.8513 - val_accuracy: 0.3407
Epoch 59/150
2813/2813 [==============================] - 171s 61ms/step - loss: 3.0308 - accuracy: 0.2964 - val_loss: 2.8373 - val_accuracy: 0.3433

Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 60/150
2813/2813 [==============================] - 177s 63ms/step - loss: 3.0097 - accuracy: 0.2988 - val_loss: 2.8185 - val_accuracy: 0.3480
Epoch 61/150
2813/2813 [==============================] - 185s 66ms/step - loss: 3.0004 - accuracy: 0.3038 - val_loss: 2.8252 - val_accuracy: 0.3478
Epoch 62/150
2813/2813 [==============================] - 173s 62ms/step - loss: 2.9784 - accuracy: 0.3079 - val_loss: 2.8100 - val_accuracy: 0.3517
Epoch 63/150
2813/2813 [==============================] - 182s 65ms/step - loss: 2.9833 - accuracy: 0.3069 - val_loss: 2.8146 - val_accuracy: 0.3439
Epoch 64/150
2813/2813 [==============================] - 176s 63ms/step - loss: 2.9756 - accuracy: 0.3114 - val_loss: 2.8105 - val_accuracy: 0.3485
Epoch 65/150
2813/2813 [==============================] - 182s 65ms/step - loss: 2.9680 - accuracy: 0.3100 - val_loss: 2.8093 - val_accuracy: 0.3527
Epoch 66/150
2813/2813 [==============================] - 177s 63ms/step - loss: 2.9706 - accuracy: 0.3098 - val_loss: 2.8324 - val_accuracy: 0.3490
Epoch 67/150
2813/2813 [==============================] - 180s 64ms/step - loss: 2.9632 - accuracy: 0.3107 - val_loss: 2.8072 - val_accuracy: 0.3474
Epoch 68/150
2813/2813 [==============================] - 175s 62ms/step - loss: 2.9518 - accuracy: 0.3129 - val_loss: 2.8280 - val_accuracy: 0.3443
Epoch 69/150
2813/2813 [==============================] - 176s 62ms/step - loss: 2.9612 - accuracy: 0.3111 - val_loss: 2.8142 - val_accuracy: 0.3455
Epoch 70/150
2813/2813 [==============================] - 180s 64ms/step - loss: 2.9520 - accuracy: 0.3124 - val_loss: 2.7979 - val_accuracy: 0.3541
Epoch 71/150
2813/2813 [==============================] - 179s 64ms/step - loss: 2.9465 - accuracy: 0.3158 - val_loss: 2.8051 - val_accuracy: 0.3501
Epoch 72/150
2813/2813 [==============================] - 176s 62ms/step - loss: 2.9449 - accuracy: 0.3132 - val_loss: 2.8100 - val_accuracy: 0.3509
Epoch 73/150
2813/2813 [==============================] - 180s 64ms/step - loss: 2.9409 - accuracy: 0.3137 - val_loss: 2.8047 - val_accuracy: 0.3530
Epoch 74/150
2813/2813 [==============================] - 178s 63ms/step - loss: 2.9373 - accuracy: 0.3156 - val_loss: 2.8093 - val_accuracy: 0.3485
Epoch 75/150
2813/2813 [==============================] - 174s 62ms/step - loss: 2.9342 - accuracy: 0.3175 - val_loss: 2.8212 - val_accuracy: 0.3514

Epoch 00075: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 76/150
2813/2813 [==============================] - 174s 62ms/step - loss: 2.9393 - accuracy: 0.3146 - val_loss: 2.8263 - val_accuracy: 0.3476
Epoch 77/150
2813/2813 [==============================] - 175s 62ms/step - loss: 2.9466 - accuracy: 0.3128 - val_loss: 2.8173 - val_accuracy: 0.3523
Epoch 78/150
2813/2813 [==============================] - 177s 63ms/step - loss: 2.9285 - accuracy: 0.3178 - val_loss: 2.7936 - val_accuracy: 0.3540
Epoch 79/150
2813/2813 [==============================] - 178s 63ms/step - loss: 2.9298 - accuracy: 0.3210 - val_loss: 2.8201 - val_accuracy: 0.3512
Epoch 80/150
2813/2813 [==============================] - 184s 65ms/step - loss: 2.9342 - accuracy: 0.3181 - val_loss: 2.8234 - val_accuracy: 0.3478
Epoch 81/150
2813/2813 [==============================] - 177s 63ms/step - loss: 2.9336 - accuracy: 0.3149 - val_loss: 2.8170 - val_accuracy: 0.3503
Epoch 82/150
2813/2813 [==============================] - 183s 65ms/step - loss: 2.9241 - accuracy: 0.3183 - val_loss: 2.8161 - val_accuracy: 0.3448
Epoch 83/150
2813/2813 [==============================] - 181s 64ms/step - loss: 2.9345 - accuracy: 0.3155 - val_loss: 2.8002 - val_accuracy: 0.3497

Epoch 00083: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 84/150
2813/2813 [==============================] - 180s 64ms/step - loss: 2.9397 - accuracy: 0.3131 - val_loss: 2.8196 - val_accuracy: 0.3514
Epoch 85/150
2813/2813 [==============================] - 180s 64ms/step - loss: 2.9351 - accuracy: 0.3149 - val_loss: 2.8120 - val_accuracy: 0.3537
Epoch 86/150
2813/2813 [==============================] - 179s 64ms/step - loss: 2.9363 - accuracy: 0.3138 - val_loss: 2.8082 - val_accuracy: 0.3513
Epoch 87/150
2813/2813 [==============================] - 179s 64ms/step - loss: 2.9396 - accuracy: 0.3132 - val_loss: 2.8205 - val_accuracy: 0.3499
Epoch 88/150
2813/2813 [==============================] - 179s 63ms/step - loss: 2.9314 - accuracy: 0.3168 - val_loss: 2.8227 - val_accuracy: 0.3528

Epoch 00088: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 89/150
2813/2813 [==============================] - 188s 67ms/step - loss: 2.9509 - accuracy: 0.3135 - val_loss: 2.7997 - val_accuracy: 0.3510
Epoch 90/150
2813/2813 [==============================] - 180s 64ms/step - loss: 2.9449 - accuracy: 0.3152 - val_loss: 2.8143 - val_accuracy: 0.3526
Epoch 91/150
2813/2813 [==============================] - 182s 65ms/step - loss: 2.9292 - accuracy: 0.3167 - val_loss: 2.8236 - val_accuracy: 0.3461
Epoch 92/150
2813/2813 [==============================] - 181s 64ms/step - loss: 2.9514 - accuracy: 0.3137 - val_loss: 2.8166 - val_accuracy: 0.3475
Epoch 93/150
2813/2813 [==============================] - 183s 65ms/step - loss: 2.9386 - accuracy: 0.3146 - val_loss: 2.8026 - val_accuracy: 0.3503

Epoch 00093: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
