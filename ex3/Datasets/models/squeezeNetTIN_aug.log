epoch,accuracy,loss,val_accuracy,val_loss
0,0.008333333767950535,5.211991310119629,0.010499999858438969,5.096246719360352
1,0.021788889542222023,4.9919915199279785,0.0340999998152256,4.844234466552734
2,0.048588890582323074,4.711381912231445,0.06480000168085098,4.573026180267334
3,0.07026666402816772,4.518750190734863,0.07980000227689743,4.438354969024658
4,0.08667777478694916,4.394830703735352,0.09279999881982803,4.3501176834106445
5,0.09741111099720001,4.302048206329346,0.10949999839067459,4.233109951019287
6,0.10869999974966049,4.211874485015869,0.11789999902248383,4.144380569458008
7,0.12042222172021866,4.135934352874756,0.1281999945640564,4.082684516906738
8,0.13017778098583221,4.056992530822754,0.13019999861717224,4.051547050476074
9,0.14221110939979553,3.980269193649292,0.14820000529289246,3.9566385746002197
10,0.15261110663414001,3.91737961769104,0.15860000252723694,3.9118995666503906
11,0.16225555539131165,3.857440948486328,0.15940000116825104,3.884432792663574
12,0.17136666178703308,3.7936506271362305,0.17069999873638153,3.807999610900879
13,0.17946666479110718,3.7382142543792725,0.18039999902248383,3.766608953475952
14,0.18667778372764587,3.684896469116211,0.19380000233650208,3.6883950233459473
15,0.19606666266918182,3.638225793838501,0.19349999725818634,3.678157329559326
16,0.20313332974910736,3.597846269607544,0.20600000023841858,3.621119976043701
17,0.21066667139530182,3.5467312335968018,0.20659999549388885,3.6190102100372314
18,0.21756666898727417,3.5069947242736816,0.20819999277591705,3.5751218795776367
19,0.2253333330154419,3.467297315597534,0.22050000727176666,3.508681535720825
20,0.23026666045188904,3.427255153656006,0.22579999268054962,3.472679615020752
21,0.23625555634498596,3.390300750732422,0.2160000056028366,3.5408074855804443
22,0.24334444105625153,3.3568382263183594,0.21879999339580536,3.5387566089630127
23,0.24914444983005524,3.3235514163970947,0.23659999668598175,3.4230756759643555
24,0.2548222243785858,3.2871086597442627,0.241799995303154,3.399468421936035
25,0.2599555552005768,3.260011911392212,0.2418999969959259,3.42775821685791
26,0.26570001244544983,3.229992628097534,0.25769999623298645,3.3200113773345947
27,0.27194443345069885,3.1947309970855713,0.25920000672340393,3.3152589797973633
28,0.27516666054725647,3.1697263717651367,0.2637999951839447,3.2986843585968018
29,0.2808666527271271,3.147489547729492,0.26330000162124634,3.3031842708587646
30,0.2849777638912201,3.1152327060699463,0.2694000005722046,3.263380289077759
31,0.29115554690361023,3.091115951538086,0.2660999894142151,3.273463487625122
32,0.29392221570014954,3.0669105052948,0.26930001378059387,3.252305746078491
33,0.29944443702697754,3.0427374839782715,0.27480000257492065,3.212156057357788
34,0.30230000615119934,3.022216558456421,0.27970001101493835,3.179128885269165
35,0.3067222237586975,2.995417356491089,0.28029999136924744,3.1882646083831787
36,0.3097444474697113,2.9763593673706055,0.28929999470710754,3.134735584259033
37,0.3141222298145294,2.9540305137634277,0.2856000065803528,3.1610257625579834
38,0.3182888925075531,2.928591251373291,0.29170000553131104,3.1356520652770996
39,0.32118889689445496,2.912946939468384,0.2912999987602234,3.1241869926452637
40,0.3245111107826233,2.8909966945648193,0.2996000051498413,3.0859947204589844
41,0.32988888025283813,2.8728556632995605,0.28519999980926514,3.168170213699341
42,0.3314777910709381,2.850984811782837,0.29919999837875366,3.105206251144409
43,0.33605554699897766,2.833122491836548,0.29510000348091125,3.114703893661499
44,0.33869999647140503,2.814100980758667,0.30090001225471497,3.0672266483306885
45,0.3424000144004822,2.798734664916992,0.29919999837875366,3.06471848487854
46,0.34496667981147766,2.777071475982666,0.30410000681877136,3.0782458782196045
47,0.3476555645465851,2.7630367279052734,0.30160000920295715,3.0941734313964844
48,0.35108888149261475,2.7517025470733643,0.3061999976634979,3.0439674854278564
49,0.3527222275733948,2.7334773540496826,0.30820000171661377,3.030984878540039
50,0.35592222213745117,2.721189498901367,0.3124000132083893,3.0285282135009766
51,0.36149999499320984,2.6951262950897217,0.3156999945640564,3.0155932903289795
52,0.3629111051559448,2.6799895763397217,0.31850001215934753,2.9955172538757324
53,0.36587777733802795,2.671541929244995,0.31769999861717224,3.00801944732666
54,0.36747777462005615,2.656550407409668,0.3240000009536743,2.976726770401001
55,0.3713222146034241,2.6392552852630615,0.32100000977516174,2.953032970428467
56,0.371788889169693,2.631409168243408,0.3158000111579895,3.021959066390991
57,0.37631112337112427,2.615769386291504,0.32170000672340393,2.982164144515991
58,0.37673333287239075,2.6008942127227783,0.3192000091075897,2.9883952140808105
59,0.381933331489563,2.588578701019287,0.32359999418258667,2.9711720943450928
60,0.3825666606426239,2.5752973556518555,0.3228999972343445,2.944598436355591
61,0.3862999975681305,2.558199405670166,0.3224000036716461,2.9626383781433105
62,0.3893222212791443,2.5474352836608887,0.3230000138282776,2.982086420059204
63,0.39153334498405457,2.538069486618042,0.3203999996185303,2.9930496215820312
64,0.39105555415153503,2.527663469314575,0.33169999718666077,2.9319944381713867
65,0.3945666551589966,2.51709246635437,0.33799999952316284,2.9121110439300537
66,0.3968222141265869,2.503955841064453,0.33379998803138733,2.937471866607666
67,0.39802223443984985,2.486018657684326,0.33889999985694885,2.9185688495635986
68,0.4024888873100281,2.4787702560424805,0.3303999900817871,2.9238088130950928
69,0.40227776765823364,2.472360372543335,0.3296999931335449,2.9492616653442383
70,0.4057888984680176,2.4576988220214844,0.3398999869823456,2.9041748046875
71,0.4082777798175812,2.449885606765747,0.33820000290870667,2.9138827323913574
72,0.40861111879348755,2.4354658126831055,0.33399999141693115,2.9597702026367188
73,0.41110000014305115,2.4249701499938965,0.33899998664855957,2.901279926300049
74,0.414511114358902,2.4152607917785645,0.3443000018596649,2.878833293914795
75,0.4147000014781952,2.4076690673828125,0.33629998564720154,2.897383689880371
76,0.4165666699409485,2.398996353149414,0.3431999981403351,2.883336305618286
77,0.419866681098938,2.389028310775757,0.34299999475479126,2.9482955932617188
78,0.42243334650993347,2.371316432952881,0.3441999852657318,2.8832526206970215
79,0.42144444584846497,2.371856451034546,0.3441999852657318,2.890143632888794
80,0.4562999904155731,2.202272653579712,0.366100013256073,2.8223695755004883
81,0.4611110985279083,2.1776273250579834,0.36640000343322754,2.797032117843628
82,0.4634000062942505,2.169142961502075,0.3634999990463257,2.802335739135742
83,0.4645777642726898,2.163142204284668,0.3605000078678131,2.8143632411956787
84,0.46369999647140503,2.161975383758545,0.3612000048160553,2.8186147212982178
85,0.4662666618824005,2.15628981590271,0.3666999936103821,2.804025888442993
86,0.46577778458595276,2.154810667037964,0.3646000027656555,2.8026421070098877
87,0.4693777859210968,2.1350748538970947,0.3628000020980835,2.8064608573913574
88,0.4709888994693756,2.129084587097168,0.3628000020980835,2.8105673789978027
89,0.47110000252723694,2.1272521018981934,0.37040001153945923,2.788843870162964
90,0.46978887915611267,2.1316287517547607,0.3619999885559082,2.81990122795105
91,0.4716888964176178,2.1274468898773193,0.36649999022483826,2.8114006519317627
92,0.47297778725624084,2.133080005645752,0.3628000020980835,2.7947545051574707
93,0.4706999957561493,2.1280229091644287,0.36489999294281006,2.808666467666626
94,0.47197777032852173,2.1286299228668213,0.365200012922287,2.7976574897766113
95,0.4711333215236664,2.127110004425049,0.362199991941452,2.806028366088867
96,0.4737222194671631,2.1243858337402344,0.36660000681877136,2.793339729309082
97,0.47246667742729187,2.128912925720215,0.3659999966621399,2.793322801589966
98,0.47153332829475403,2.1286556720733643,0.36570000648498535,2.8061959743499756
99,0.47192221879959106,2.1246697902679443,0.3617999851703644,2.8179733753204346
100,0.4718666672706604,2.129532814025879,0.36399999260902405,2.8086817264556885
101,0.4740999937057495,2.122602939605713,0.36570000648498535,2.7966339588165283
102,0.47037777304649353,2.1295559406280518,0.3668999969959259,2.807476282119751
103,0.47314444184303284,2.125276803970337,0.3686000108718872,2.8016374111175537
104,0.4695444405078888,2.129063367843628,0.36880001425743103,2.8146793842315674
105,0.46994444727897644,2.1255862712860107,0.3684000074863434,2.7948617935180664
106,0.47380000352859497,2.1248958110809326,0.3589000105857849,2.810331106185913
107,0.4731999933719635,2.1250736713409424,0.37070000171661377,2.8011882305145264
108,0.47171109914779663,2.125575065612793,0.37119999527931213,2.792210102081299
109,0.4726888835430145,2.121211051940918,0.3682999908924103,2.7915616035461426
110,0.47058889269828796,2.125474691390991,0.3619000017642975,2.814483165740967
111,0.4720555543899536,2.1239683628082275,0.36809998750686646,2.800778865814209
112,0.4717000126838684,2.128300189971924,0.36169999837875366,2.8093199729919434
113,0.47174444794654846,2.1237146854400635,0.364300012588501,2.8069231510162354
114,0.4702666699886322,2.1284542083740234,0.36250001192092896,2.814617156982422

Epoch 1/150
1407/1407 [==============================] - 172s 116ms/step - loss: 5.2722 - accuracy: 0.0064 - val_loss: 5.0962 - val_accuracy: 0.0105
Epoch 2/150
1407/1407 [==============================] - 159s 113ms/step - loss: 5.0558 - accuracy: 0.0162 - val_loss: 4.8442 - val_accuracy: 0.0341
Epoch 3/150
1407/1407 [==============================] - 159s 113ms/step - loss: 4.7727 - accuracy: 0.0426 - val_loss: 4.5730 - val_accuracy: 0.0648
Epoch 4/150
1407/1407 [==============================] - 156s 111ms/step - loss: 4.5495 - accuracy: 0.0654 - val_loss: 4.4384 - val_accuracy: 0.0798
Epoch 5/150
1407/1407 [==============================] - 160s 114ms/step - loss: 4.4191 - accuracy: 0.0838 - val_loss: 4.3501 - val_accuracy: 0.0928
Epoch 6/150
1407/1407 [==============================] - 158s 112ms/step - loss: 4.3158 - accuracy: 0.0950 - val_loss: 4.2331 - val_accuracy: 0.1095
Epoch 7/150
1407/1407 [==============================] - 160s 114ms/step - loss: 4.2214 - accuracy: 0.1068 - val_loss: 4.1444 - val_accuracy: 0.1179
Epoch 8/150
1407/1407 [==============================] - 161s 114ms/step - loss: 4.1468 - accuracy: 0.1194 - val_loss: 4.0827 - val_accuracy: 0.1282
Epoch 9/150
1407/1407 [==============================] - 163s 116ms/step - loss: 4.0706 - accuracy: 0.1272 - val_loss: 4.0515 - val_accuracy: 0.1302
Epoch 10/150
1407/1407 [==============================] - 160s 114ms/step - loss: 3.9930 - accuracy: 0.1404 - val_loss: 3.9566 - val_accuracy: 0.1482
Epoch 11/150
1407/1407 [==============================] - 164s 116ms/step - loss: 3.9202 - accuracy: 0.1509 - val_loss: 3.9119 - val_accuracy: 0.1586
Epoch 12/150
1407/1407 [==============================] - 165s 117ms/step - loss: 3.8640 - accuracy: 0.1591 - val_loss: 3.8844 - val_accuracy: 0.1594
Epoch 13/150
1407/1407 [==============================] - 165s 117ms/step - loss: 3.8085 - accuracy: 0.1695 - val_loss: 3.8080 - val_accuracy: 0.1707
Epoch 14/150
1407/1407 [==============================] - 161s 115ms/step - loss: 3.7459 - accuracy: 0.1782 - val_loss: 3.7666 - val_accuracy: 0.1804
Epoch 15/150
1407/1407 [==============================] - 162s 115ms/step - loss: 3.6871 - accuracy: 0.1877 - val_loss: 3.6884 - val_accuracy: 0.1938
Epoch 16/150
1407/1407 [==============================] - 162s 115ms/step - loss: 3.6361 - accuracy: 0.1961 - val_loss: 3.6782 - val_accuracy: 0.1935
Epoch 17/150
1407/1407 [==============================] - 162s 115ms/step - loss: 3.5984 - accuracy: 0.2030 - val_loss: 3.6211 - val_accuracy: 0.2060
Epoch 18/150
1407/1407 [==============================] - 159s 113ms/step - loss: 3.5444 - accuracy: 0.2088 - val_loss: 3.6190 - val_accuracy: 0.2066
Epoch 19/150
1407/1407 [==============================] - 161s 114ms/step - loss: 3.4982 - accuracy: 0.2185 - val_loss: 3.5751 - val_accuracy: 0.2082
Epoch 20/150
1407/1407 [==============================] - 158s 112ms/step - loss: 3.4687 - accuracy: 0.2248 - val_loss: 3.5087 - val_accuracy: 0.2205
Epoch 21/150
1407/1407 [==============================] - 161s 115ms/step - loss: 3.4218 - accuracy: 0.2289 - val_loss: 3.4727 - val_accuracy: 0.2258
Epoch 22/150
1407/1407 [==============================] - 161s 114ms/step - loss: 3.3799 - accuracy: 0.2395 - val_loss: 3.5408 - val_accuracy: 0.2160
Epoch 23/150
1407/1407 [==============================] - 159s 113ms/step - loss: 3.3623 - accuracy: 0.2425 - val_loss: 3.5388 - val_accuracy: 0.2188
Epoch 24/150
1407/1407 [==============================] - 158s 112ms/step - loss: 3.3159 - accuracy: 0.2515 - val_loss: 3.4231 - val_accuracy: 0.2366
Epoch 25/150
1407/1407 [==============================] - 163s 116ms/step - loss: 3.2775 - accuracy: 0.2551 - val_loss: 3.3995 - val_accuracy: 0.2418
Epoch 26/150
1407/1407 [==============================] - 159s 113ms/step - loss: 3.2646 - accuracy: 0.2587 - val_loss: 3.4278 - val_accuracy: 0.2419
Epoch 27/150
1407/1407 [==============================] - 162s 115ms/step - loss: 3.2373 - accuracy: 0.2635 - val_loss: 3.3200 - val_accuracy: 0.2577
Epoch 28/150
1407/1407 [==============================] - 163s 116ms/step - loss: 3.2026 - accuracy: 0.2703 - val_loss: 3.3153 - val_accuracy: 0.2592
Epoch 29/150
1407/1407 [==============================] - 164s 116ms/step - loss: 3.1654 - accuracy: 0.2758 - val_loss: 3.2987 - val_accuracy: 0.2638
Epoch 30/150
1407/1407 [==============================] - 163s 116ms/step - loss: 3.1401 - accuracy: 0.2832 - val_loss: 3.3032 - val_accuracy: 0.2633
Epoch 31/150
1407/1407 [==============================] - 164s 116ms/step - loss: 3.1188 - accuracy: 0.2868 - val_loss: 3.2634 - val_accuracy: 0.2694
Epoch 32/150
1407/1407 [==============================] - 164s 117ms/step - loss: 3.0852 - accuracy: 0.2892 - val_loss: 3.2735 - val_accuracy: 0.2661
Epoch 33/150
1407/1407 [==============================] - 163s 116ms/step - loss: 3.0536 - accuracy: 0.2956 - val_loss: 3.2523 - val_accuracy: 0.2693
Epoch 34/150
1407/1407 [==============================] - 163s 116ms/step - loss: 3.0354 - accuracy: 0.3013 - val_loss: 3.2122 - val_accuracy: 0.2748
Epoch 35/150
1407/1407 [==============================] - 162s 115ms/step - loss: 3.0264 - accuracy: 0.3020 - val_loss: 3.1791 - val_accuracy: 0.2797
Epoch 36/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.9873 - accuracy: 0.3074 - val_loss: 3.1883 - val_accuracy: 0.2803
Epoch 37/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.9614 - accuracy: 0.3123 - val_loss: 3.1347 - val_accuracy: 0.2893
Epoch 38/150
1407/1407 [==============================] - 161s 114ms/step - loss: 2.9413 - accuracy: 0.3174 - val_loss: 3.1610 - val_accuracy: 0.2856
Epoch 39/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.9257 - accuracy: 0.3159 - val_loss: 3.1357 - val_accuracy: 0.2917
Epoch 40/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.9018 - accuracy: 0.3224 - val_loss: 3.1242 - val_accuracy: 0.2913
Epoch 41/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.8812 - accuracy: 0.3270 - val_loss: 3.0860 - val_accuracy: 0.2996
Epoch 42/150
1407/1407 [==============================] - 164s 117ms/step - loss: 2.8457 - accuracy: 0.3356 - val_loss: 3.1682 - val_accuracy: 0.2852
Epoch 43/150
1407/1407 [==============================] - 165s 117ms/step - loss: 2.8434 - accuracy: 0.3337 - val_loss: 3.1052 - val_accuracy: 0.2992
Epoch 44/150
1407/1407 [==============================] - 161s 115ms/step - loss: 2.8336 - accuracy: 0.3368 - val_loss: 3.1147 - val_accuracy: 0.2951
Epoch 45/150
1407/1407 [==============================] - 167s 119ms/step - loss: 2.7995 - accuracy: 0.3413 - val_loss: 3.0672 - val_accuracy: 0.3009
Epoch 46/150
1407/1407 [==============================] - 167s 118ms/step - loss: 2.7914 - accuracy: 0.3447 - val_loss: 3.0647 - val_accuracy: 0.2992
Epoch 47/150
1407/1407 [==============================] - 164s 116ms/step - loss: 2.7549 - accuracy: 0.3483 - val_loss: 3.0782 - val_accuracy: 0.3041
Epoch 48/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.7613 - accuracy: 0.3492 - val_loss: 3.0942 - val_accuracy: 0.3016
Epoch 49/150
1407/1407 [==============================] - 165s 117ms/step - loss: 2.7355 - accuracy: 0.3540 - val_loss: 3.0440 - val_accuracy: 0.3062
Epoch 50/150
1407/1407 [==============================] - 165s 117ms/step - loss: 2.7320 - accuracy: 0.3519 - val_loss: 3.0310 - val_accuracy: 0.3082
Epoch 51/150
1407/1407 [==============================] - 164s 116ms/step - loss: 2.7100 - accuracy: 0.3571 - val_loss: 3.0285 - val_accuracy: 0.3124
Epoch 52/150
1407/1407 [==============================] - 159s 113ms/step - loss: 2.6783 - accuracy: 0.3636 - val_loss: 3.0156 - val_accuracy: 0.3157
Epoch 53/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.6668 - accuracy: 0.3656 - val_loss: 2.9955 - val_accuracy: 0.3185
Epoch 54/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.6579 - accuracy: 0.3668 - val_loss: 3.0080 - val_accuracy: 0.3177
Epoch 55/150
1407/1407 [==============================] - 164s 116ms/step - loss: 2.6479 - accuracy: 0.3701 - val_loss: 2.9767 - val_accuracy: 0.3240
Epoch 56/150
1407/1407 [==============================] - 161s 115ms/step - loss: 2.6316 - accuracy: 0.3723 - val_loss: 2.9530 - val_accuracy: 0.3210
Epoch 57/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.6106 - accuracy: 0.3748 - val_loss: 3.0220 - val_accuracy: 0.3158
Epoch 58/150
1407/1407 [==============================] - 160s 113ms/step - loss: 2.6105 - accuracy: 0.3784 - val_loss: 2.9822 - val_accuracy: 0.3217
Epoch 59/150
1407/1407 [==============================] - 165s 117ms/step - loss: 2.5832 - accuracy: 0.3797 - val_loss: 2.9884 - val_accuracy: 0.3192
Epoch 60/150
1407/1407 [==============================] - 168s 119ms/step - loss: 2.5744 - accuracy: 0.3843 - val_loss: 2.9712 - val_accuracy: 0.3236
Epoch 61/150
1407/1407 [==============================] - 168s 119ms/step - loss: 2.5662 - accuracy: 0.3824 - val_loss: 2.9446 - val_accuracy: 0.3229
Epoch 62/150
1407/1407 [==============================] - 168s 120ms/step - loss: 2.5520 - accuracy: 0.3877 - val_loss: 2.9626 - val_accuracy: 0.3224
Epoch 63/150
1407/1407 [==============================] - 171s 121ms/step - loss: 2.5370 - accuracy: 0.3918 - val_loss: 2.9821 - val_accuracy: 0.3230
Epoch 64/150
1407/1407 [==============================] - 169s 120ms/step - loss: 2.5322 - accuracy: 0.3932 - val_loss: 2.9930 - val_accuracy: 0.3204
Epoch 65/150
1407/1407 [==============================] - 171s 122ms/step - loss: 2.5042 - accuracy: 0.3959 - val_loss: 2.9320 - val_accuracy: 0.3317
Epoch 66/150
1407/1407 [==============================] - 172s 122ms/step - loss: 2.4932 - accuracy: 0.3988 - val_loss: 2.9121 - val_accuracy: 0.3380
Epoch 67/150
1407/1407 [==============================] - 171s 122ms/step - loss: 2.4920 - accuracy: 0.3974 - val_loss: 2.9375 - val_accuracy: 0.3338
Epoch 68/150
1407/1407 [==============================] - 170s 121ms/step - loss: 2.4715 - accuracy: 0.4016 - val_loss: 2.9186 - val_accuracy: 0.3389
Epoch 69/150
1407/1407 [==============================] - 170s 120ms/step - loss: 2.4686 - accuracy: 0.4006 - val_loss: 2.9238 - val_accuracy: 0.3304
Epoch 70/150
1407/1407 [==============================] - 165s 117ms/step - loss: 2.4692 - accuracy: 0.4028 - val_loss: 2.9493 - val_accuracy: 0.3297
Epoch 71/150
1407/1407 [==============================] - 166s 118ms/step - loss: 2.4419 - accuracy: 0.4078 - val_loss: 2.9042 - val_accuracy: 0.3399
Epoch 72/150
1407/1407 [==============================] - 164s 117ms/step - loss: 2.4391 - accuracy: 0.4113 - val_loss: 2.9139 - val_accuracy: 0.3382
Epoch 73/150
1407/1407 [==============================] - 164s 116ms/step - loss: 2.4187 - accuracy: 0.4126 - val_loss: 2.9598 - val_accuracy: 0.3340
Epoch 74/150
1407/1407 [==============================] - 164s 116ms/step - loss: 2.4093 - accuracy: 0.4140 - val_loss: 2.9013 - val_accuracy: 0.3390
Epoch 75/150
1407/1407 [==============================] - 165s 118ms/step - loss: 2.4039 - accuracy: 0.4166 - val_loss: 2.8788 - val_accuracy: 0.3443
Epoch 76/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.3804 - accuracy: 0.4204 - val_loss: 2.8974 - val_accuracy: 0.3363
Epoch 77/150
1407/1407 [==============================] - 164s 116ms/step - loss: 2.3867 - accuracy: 0.4170 - val_loss: 2.8833 - val_accuracy: 0.3432
Epoch 78/150
1407/1407 [==============================] - 161s 115ms/step - loss: 2.3756 - accuracy: 0.4217 - val_loss: 2.9483 - val_accuracy: 0.3430
Epoch 79/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.3687 - accuracy: 0.4230 - val_loss: 2.8833 - val_accuracy: 0.3442
Epoch 80/150
1407/1407 [==============================] - 161s 114ms/step - loss: 2.3488 - accuracy: 0.4278 - val_loss: 2.8901 - val_accuracy: 0.3442

Epoch 00080: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 81/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.2145 - accuracy: 0.4543 - val_loss: 2.8224 - val_accuracy: 0.3661
Epoch 82/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.1743 - accuracy: 0.4619 - val_loss: 2.7970 - val_accuracy: 0.3664
Epoch 83/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.1716 - accuracy: 0.4609 - val_loss: 2.8023 - val_accuracy: 0.3635
Epoch 84/150
1407/1407 [==============================] - 159s 113ms/step - loss: 2.1742 - accuracy: 0.4626 - val_loss: 2.8144 - val_accuracy: 0.3605
Epoch 85/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.1766 - accuracy: 0.4582 - val_loss: 2.8186 - val_accuracy: 0.3612
Epoch 86/150
1407/1407 [==============================] - 161s 114ms/step - loss: 2.1511 - accuracy: 0.4678 - val_loss: 2.8040 - val_accuracy: 0.3667
Epoch 87/150
1407/1407 [==============================] - 166s 118ms/step - loss: 2.1497 - accuracy: 0.4660 - val_loss: 2.8026 - val_accuracy: 0.3646

Epoch 00087: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 88/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.1320 - accuracy: 0.4701 - val_loss: 2.8065 - val_accuracy: 0.3628
Epoch 89/150
1407/1407 [==============================] - 166s 118ms/step - loss: 2.1333 - accuracy: 0.4688 - val_loss: 2.8106 - val_accuracy: 0.3628
Epoch 90/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.1370 - accuracy: 0.4682 - val_loss: 2.7888 - val_accuracy: 0.3704
Epoch 91/150
1407/1407 [==============================] - 169s 120ms/step - loss: 2.1275 - accuracy: 0.4704 - val_loss: 2.8199 - val_accuracy: 0.3620
Epoch 92/150
1407/1407 [==============================] - 166s 118ms/step - loss: 2.1216 - accuracy: 0.4718 - val_loss: 2.8114 - val_accuracy: 0.3665
Epoch 93/150
1407/1407 [==============================] - 166s 118ms/step - loss: 2.1426 - accuracy: 0.4725 - val_loss: 2.7948 - val_accuracy: 0.3628
Epoch 94/150
1407/1407 [==============================] - 164s 117ms/step - loss: 2.1290 - accuracy: 0.4706 - val_loss: 2.8087 - val_accuracy: 0.3649
Epoch 95/150
1407/1407 [==============================] - 168s 119ms/step - loss: 2.1295 - accuracy: 0.4717 - val_loss: 2.7977 - val_accuracy: 0.3652

Epoch 00095: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 96/150
1407/1407 [==============================] - 165s 117ms/step - loss: 2.1266 - accuracy: 0.4725 - val_loss: 2.8060 - val_accuracy: 0.3622
Epoch 97/150
1407/1407 [==============================] - 164s 116ms/step - loss: 2.1275 - accuracy: 0.4719 - val_loss: 2.7933 - val_accuracy: 0.3666
Epoch 98/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.1202 - accuracy: 0.4737 - val_loss: 2.7933 - val_accuracy: 0.3660
Epoch 99/150
1407/1407 [==============================] - 164s 117ms/step - loss: 2.1398 - accuracy: 0.4698 - val_loss: 2.8062 - val_accuracy: 0.3657
Epoch 100/150
1407/1407 [==============================] - 159s 113ms/step - loss: 2.1135 - accuracy: 0.4747 - val_loss: 2.8180 - val_accuracy: 0.3618

Epoch 00100: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 101/150
1407/1407 [==============================] - 168s 119ms/step - loss: 2.1359 - accuracy: 0.4713 - val_loss: 2.8087 - val_accuracy: 0.3640
Epoch 102/150
1407/1407 [==============================] - 163s 116ms/step - loss: 2.1277 - accuracy: 0.4708 - val_loss: 2.7966 - val_accuracy: 0.3657
Epoch 103/150
1407/1407 [==============================] - 165s 117ms/step - loss: 2.1296 - accuracy: 0.4718 - val_loss: 2.8075 - val_accuracy: 0.3669
Epoch 104/150
1407/1407 [==============================] - 162s 115ms/step - loss: 2.1313 - accuracy: 0.4727 - val_loss: 2.8016 - val_accuracy: 0.3686
Epoch 105/150
1407/1407 [==============================] - 164s 117ms/step - loss: 2.1278 - accuracy: 0.4695 - val_loss: 2.8147 - val_accuracy: 0.3688

Epoch 00105: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 106/150
1407/1407 [==============================] - 159s 113ms/step - loss: 2.1228 - accuracy: 0.4708 - val_loss: 2.7949 - val_accuracy: 0.3684
Epoch 107/150
1407/1407 [==============================] - 161s 114ms/step - loss: 2.1260 - accuracy: 0.4737 - val_loss: 2.8103 - val_accuracy: 0.3589
Epoch 108/150
1407/1407 [==============================] - 159s 113ms/step - loss: 2.1349 - accuracy: 0.4704 - val_loss: 2.8012 - val_accuracy: 0.3707
Epoch 109/150
1407/1407 [==============================] - 158s 112ms/step - loss: 2.1188 - accuracy: 0.4755 - val_loss: 2.7922 - val_accuracy: 0.3712
Epoch 110/150
1407/1407 [==============================] - 158s 112ms/step - loss: 2.1200 - accuracy: 0.4730 - val_loss: 2.7916 - val_accuracy: 0.3683

Epoch 00110: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.
Epoch 111/150
1407/1407 [==============================] - 158s 112ms/step - loss: 2.1337 - accuracy: 0.4689 - val_loss: 2.8145 - val_accuracy: 0.3619
Epoch 112/150
1407/1407 [==============================] - 154s 110ms/step - loss: 2.1163 - accuracy: 0.4714 - val_loss: 2.8008 - val_accuracy: 0.3681
Epoch 113/150
1407/1407 [==============================] - 159s 113ms/step - loss: 2.1299 - accuracy: 0.4723 - val_loss: 2.8093 - val_accuracy: 0.3617
Epoch 114/150
1407/1407 [==============================] - 155s 110ms/step - loss: 2.1302 - accuracy: 0.4686 - val_loss: 2.8069 - val_accuracy: 0.3643
Epoch 115/150
1407/1407 [==============================] - 157s 112ms/step - loss: 2.1197 - accuracy: 0.4727 - val_loss: 2.8146 - val_accuracy: 0.3625

Epoch 00115: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.