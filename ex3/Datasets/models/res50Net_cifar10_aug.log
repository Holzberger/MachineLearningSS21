epoch,accuracy,loss,val_accuracy,val_loss
0,0.12573333084583282,2.696897506713867,0.15219999849796295,2.4384424686431885
1,0.15386666357517242,2.416126012802124,0.1720000058412552,2.3196463584899902
2,0.1857111155986786,2.267612934112549,0.1860000044107437,2.181978702545166
3,0.208688884973526,2.165781021118164,0.15440000593662262,2.766801357269287
4,0.22608888149261475,2.1002376079559326,0.2070000022649765,2.130361318588257
5,0.2514444589614868,2.0438778400421143,0.23260000348091125,2.151921033859253
6,0.26268887519836426,2.005138635635376,0.17260000109672546,2.438913345336914
7,0.277222216129303,1.9747874736785889,0.15680000185966492,2.2318220138549805
8,0.29188889265060425,1.9423500299453735,0.17759999632835388,2.398897647857666
9,0.30906665325164795,1.9132065773010254,0.1136000007390976,4.822667598724365
10,0.31886667013168335,1.8882949352264404,0.24860000610351562,2.2670395374298096
11,0.3249777853488922,1.883028268814087,0.30399999022483826,1.989780068397522
12,0.3256666660308838,1.8744157552719116,0.3124000132083893,1.903786540031433
13,0.328511118888855,1.868281602859497,0.33239999413490295,1.8802169561386108
14,0.3300666809082031,1.863533854484558,0.35420000553131104,1.8044570684432983
15,0.335999995470047,1.851263403892517,0.3190000057220459,1.98191499710083
16,0.3359777629375458,1.847415566444397,0.32120001316070557,1.9241389036178589
17,0.33719998598098755,1.8463152647018433,0.29600000381469727,2.009692668914795
18,0.33748888969421387,1.844391107559204,0.3837999999523163,1.770361304283142
19,0.34262222051620483,1.8425679206848145,0.3531999886035919,1.8130674362182617
20,0.3425999879837036,1.8369216918945312,0.35899999737739563,1.785792589187622
21,0.34282222390174866,1.8353465795516968,0.36340001225471497,1.786502480506897
22,0.3486666679382324,1.8237475156784058,0.36340001225471497,1.780373215675354
23,0.34977778792381287,1.8217196464538574,0.3375999927520752,1.8429487943649292
24,0.35055556893348694,1.8241993188858032,0.4138000011444092,1.6715607643127441
25,0.3518444299697876,1.8198965787887573,0.40119999647140503,1.6963353157043457
26,0.35066667199134827,1.819090485572815,0.4099999964237213,1.6808295249938965
27,0.3501555621623993,1.821210265159607,0.4083999991416931,1.6878870725631714
28,0.3484666645526886,1.8181740045547485,0.40700000524520874,1.697817325592041
29,0.3521111011505127,1.8167227506637573,0.40299999713897705,1.673906683921814
30,0.3522000014781952,1.8206007480621338,0.4106000065803528,1.6790755987167358
31,0.35064443945884705,1.8170530796051025,0.41679999232292175,1.678682804107666
32,0.34824445843696594,1.8244117498397827,0.40959998965263367,1.685396432876587
33,0.3484888970851898,1.8202338218688965,0.41499999165534973,1.6782785654067993
34,0.35271111130714417,1.8151177167892456,0.41019999980926514,1.6715929508209229
35,0.3490222096443176,1.8199902772903442,0.40880000591278076,1.6781667470932007
36,0.35011109709739685,1.8160003423690796,0.4146000146865845,1.6785138845443726
37,0.3531111180782318,1.8155882358551025,0.41839998960494995,1.670026421546936
38,0.3517555594444275,1.8120427131652832,0.41019999980926514,1.676881194114685
39,0.3547777831554413,1.8151923418045044,0.41659998893737793,1.665010929107666
40,0.3515999913215637,1.820756196975708,0.40700000524520874,1.681026577949524
41,0.3533777892589569,1.8124279975891113,0.4097999930381775,1.6777756214141846
42,0.3520444333553314,1.8182015419006348,0.4074000120162964,1.6859562397003174
43,0.3485777676105499,1.8210972547531128,0.40939998626708984,1.6740773916244507
44,0.3472222089767456,1.8223233222961426,0.41819998621940613,1.6744791269302368
45,0.3488222360610962,1.8195809125900269,0.40540000796318054,1.6865146160125732
46,0.35244444012641907,1.8183174133300781,0.4153999984264374,1.6669234037399292
47,0.35528889298439026,1.8074628114700317,0.41100001335144043,1.6738927364349365
48,0.3518444299697876,1.8146439790725708,0.4043999910354614,1.6885168552398682
49,0.3499111235141754,1.8224486112594604,0.40720000863075256,1.6816176176071167
50,0.3513111174106598,1.8139235973358154,0.41780000925064087,1.6711992025375366
51,0.347044438123703,1.8187229633331299,0.40119999647140503,1.6887974739074707
52,0.3486666679382324,1.8187572956085205,0.4147999882698059,1.6750166416168213
53,0.3522222340106964,1.819853663444519,0.4065999984741211,1.682133436203003
54,0.34602221846580505,1.8225656747817993,0.4124000072479248,1.673354148864746
55,0.3496222198009491,1.8178043365478516,0.41839998960494995,1.671322226524353
56,0.3487555682659149,1.8203938007354736,0.40720000863075256,1.6842762231826782
57,0.3523777723312378,1.820383906364441,0.4115999937057495,1.6756882667541504
58,0.35368889570236206,1.8170167207717896,0.4092000126838684,1.6769566535949707
59,0.34895554184913635,1.818871021270752,0.40880000591278076,1.6708797216415405
60,0.34951111674308777,1.815685749053955,0.4059999883174896,1.6862989664077759
61,0.35128888487815857,1.8211497068405151,0.4097999930381775,1.6727460622787476
62,0.34957778453826904,1.8193762302398682,0.4099999964237213,1.671899437904358
63,0.35064443945884705,1.8183985948562622,0.40720000863075256,1.668849229812622
64,0.3499777913093567,1.818102478981018,0.4075999855995178,1.6796048879623413

Epoch 1/150
704/704 [==============================] - 42s 53ms/step - loss: 2.6969 - accuracy: 0.1257 - val_loss: 2.4384 - val_accuracy: 0.1522
Epoch 2/150
704/704 [==============================] - 35s 50ms/step - loss: 2.4161 - accuracy: 0.1539 - val_loss: 2.3196 - val_accuracy: 0.1720
Epoch 3/150
704/704 [==============================] - 35s 49ms/step - loss: 2.2676 - accuracy: 0.1857 - val_loss: 2.1820 - val_accuracy: 0.1860
Epoch 4/150
704/704 [==============================] - 36s 52ms/step - loss: 2.1658 - accuracy: 0.2087 - val_loss: 2.7668 - val_accuracy: 0.1544
Epoch 5/150
704/704 [==============================] - 35s 50ms/step - loss: 2.1002 - accuracy: 0.2261 - val_loss: 2.1304 - val_accuracy: 0.2070
Epoch 6/150
704/704 [==============================] - 35s 50ms/step - loss: 2.0439 - accuracy: 0.2514 - val_loss: 2.1519 - val_accuracy: 0.2326
Epoch 7/150
704/704 [==============================] - 36s 51ms/step - loss: 2.0051 - accuracy: 0.2627 - val_loss: 2.4389 - val_accuracy: 0.1726
Epoch 8/150
704/704 [==============================] - 35s 49ms/step - loss: 1.9748 - accuracy: 0.2772 - val_loss: 2.2318 - val_accuracy: 0.1568
Epoch 9/150
704/704 [==============================] - 37s 53ms/step - loss: 1.9424 - accuracy: 0.2919 - val_loss: 2.3989 - val_accuracy: 0.1776
Epoch 10/150
704/704 [==============================] - 34s 48ms/step - loss: 1.9132 - accuracy: 0.3091 - val_loss: 4.8227 - val_accuracy: 0.1136

Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 11/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8883 - accuracy: 0.3189 - val_loss: 2.2670 - val_accuracy: 0.2486
Epoch 12/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8830 - accuracy: 0.3250 - val_loss: 1.9898 - val_accuracy: 0.3040
Epoch 13/150
704/704 [==============================] - 33s 48ms/step - loss: 1.8744 - accuracy: 0.3257 - val_loss: 1.9038 - val_accuracy: 0.3124
Epoch 14/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8683 - accuracy: 0.3285 - val_loss: 1.8802 - val_accuracy: 0.3324
Epoch 15/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8635 - accuracy: 0.3301 - val_loss: 1.8045 - val_accuracy: 0.3542
Epoch 16/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8513 - accuracy: 0.3360 - val_loss: 1.9819 - val_accuracy: 0.3190
Epoch 17/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8474 - accuracy: 0.3360 - val_loss: 1.9241 - val_accuracy: 0.3212
Epoch 18/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8463 - accuracy: 0.3372 - val_loss: 2.0097 - val_accuracy: 0.2960
Epoch 19/150
704/704 [==============================] - 37s 52ms/step - loss: 1.8444 - accuracy: 0.3375 - val_loss: 1.7704 - val_accuracy: 0.3838
Epoch 20/150
704/704 [==============================] - 36s 52ms/step - loss: 1.8426 - accuracy: 0.3426 - val_loss: 1.8131 - val_accuracy: 0.3532
Epoch 21/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8369 - accuracy: 0.3426 - val_loss: 1.7858 - val_accuracy: 0.3590
Epoch 22/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8353 - accuracy: 0.3428 - val_loss: 1.7865 - val_accuracy: 0.3634
Epoch 23/150
704/704 [==============================] - 35s 49ms/step - loss: 1.8237 - accuracy: 0.3487 - val_loss: 1.7804 - val_accuracy: 0.3634
Epoch 24/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8217 - accuracy: 0.3498 - val_loss: 1.8429 - val_accuracy: 0.3376

Epoch 00024: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 25/150
704/704 [==============================] - 33s 48ms/step - loss: 1.8242 - accuracy: 0.3506 - val_loss: 1.6716 - val_accuracy: 0.4138
Epoch 26/150
704/704 [==============================] - 37s 52ms/step - loss: 1.8199 - accuracy: 0.3518 - val_loss: 1.6963 - val_accuracy: 0.4012
Epoch 27/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8191 - accuracy: 0.3507 - val_loss: 1.6808 - val_accuracy: 0.4100
Epoch 28/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8212 - accuracy: 0.3502 - val_loss: 1.6879 - val_accuracy: 0.4084
Epoch 29/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8182 - accuracy: 0.3485 - val_loss: 1.6978 - val_accuracy: 0.4070
Epoch 30/150
704/704 [==============================] - 37s 52ms/step - loss: 1.8167 - accuracy: 0.3521 - val_loss: 1.6739 - val_accuracy: 0.4030

Epoch 00030: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 31/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8206 - accuracy: 0.3522 - val_loss: 1.6791 - val_accuracy: 0.4106
Epoch 32/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8171 - accuracy: 0.3506 - val_loss: 1.6787 - val_accuracy: 0.4168
Epoch 33/150
704/704 [==============================] - 35s 49ms/step - loss: 1.8244 - accuracy: 0.3482 - val_loss: 1.6854 - val_accuracy: 0.4096
Epoch 34/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8202 - accuracy: 0.3485 - val_loss: 1.6783 - val_accuracy: 0.4150
Epoch 35/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8151 - accuracy: 0.3527 - val_loss: 1.6716 - val_accuracy: 0.4102

Epoch 00035: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 36/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8200 - accuracy: 0.3490 - val_loss: 1.6782 - val_accuracy: 0.4088
Epoch 37/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8160 - accuracy: 0.3501 - val_loss: 1.6785 - val_accuracy: 0.4146
Epoch 38/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8156 - accuracy: 0.3531 - val_loss: 1.6700 - val_accuracy: 0.4184
Epoch 39/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8120 - accuracy: 0.3518 - val_loss: 1.6769 - val_accuracy: 0.4102
Epoch 40/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8152 - accuracy: 0.3548 - val_loss: 1.6650 - val_accuracy: 0.4166
Epoch 41/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8208 - accuracy: 0.3516 - val_loss: 1.6810 - val_accuracy: 0.4070
Epoch 42/150
704/704 [==============================] - 35s 49ms/step - loss: 1.8124 - accuracy: 0.3534 - val_loss: 1.6778 - val_accuracy: 0.4098
Epoch 43/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8182 - accuracy: 0.3520 - val_loss: 1.6860 - val_accuracy: 0.4074
Epoch 44/150
704/704 [==============================] - 34s 49ms/step - loss: 1.8211 - accuracy: 0.3486 - val_loss: 1.6741 - val_accuracy: 0.4094
Epoch 45/150
704/704 [==============================] - 36s 52ms/step - loss: 1.8223 - accuracy: 0.3472 - val_loss: 1.6745 - val_accuracy: 0.4182

Epoch 00045: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 46/150
704/704 [==============================] - 38s 54ms/step - loss: 1.8196 - accuracy: 0.3488 - val_loss: 1.6865 - val_accuracy: 0.4054
Epoch 47/150
704/704 [==============================] - 33s 47ms/step - loss: 1.8183 - accuracy: 0.3524 - val_loss: 1.6669 - val_accuracy: 0.4154
Epoch 48/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8075 - accuracy: 0.3553 - val_loss: 1.6739 - val_accuracy: 0.4110
Epoch 49/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8146 - accuracy: 0.3518 - val_loss: 1.6885 - val_accuracy: 0.4044
Epoch 50/150
704/704 [==============================] - 33s 48ms/step - loss: 1.8224 - accuracy: 0.3499 - val_loss: 1.6816 - val_accuracy: 0.4072

Epoch 00050: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.
Epoch 51/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8139 - accuracy: 0.3513 - val_loss: 1.6712 - val_accuracy: 0.4178
Epoch 52/150
704/704 [==============================] - 33s 47ms/step - loss: 1.8187 - accuracy: 0.3470 - val_loss: 1.6888 - val_accuracy: 0.4012
Epoch 53/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8188 - accuracy: 0.3487 - val_loss: 1.6750 - val_accuracy: 0.4148
Epoch 54/150
704/704 [==============================] - 33s 47ms/step - loss: 1.8199 - accuracy: 0.3522 - val_loss: 1.6821 - val_accuracy: 0.4066
Epoch 55/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8226 - accuracy: 0.3460 - val_loss: 1.6734 - val_accuracy: 0.4124

Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.
Epoch 56/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8178 - accuracy: 0.3496 - val_loss: 1.6713 - val_accuracy: 0.4184
Epoch 57/150
704/704 [==============================] - 38s 54ms/step - loss: 1.8204 - accuracy: 0.3488 - val_loss: 1.6843 - val_accuracy: 0.4072
Epoch 58/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8204 - accuracy: 0.3524 - val_loss: 1.6757 - val_accuracy: 0.4116
Epoch 59/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8170 - accuracy: 0.3537 - val_loss: 1.6770 - val_accuracy: 0.4092
Epoch 60/150
704/704 [==============================] - 35s 50ms/step - loss: 1.8189 - accuracy: 0.3490 - val_loss: 1.6709 - val_accuracy: 0.4088

Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.
Epoch 61/150
704/704 [==============================] - 37s 52ms/step - loss: 1.8157 - accuracy: 0.3495 - val_loss: 1.6863 - val_accuracy: 0.4060
Epoch 62/150
704/704 [==============================] - 34s 48ms/step - loss: 1.8211 - accuracy: 0.3513 - val_loss: 1.6727 - val_accuracy: 0.4098
Epoch 63/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8194 - accuracy: 0.3496 - val_loss: 1.6719 - val_accuracy: 0.4100
Epoch 64/150
704/704 [==============================] - 33s 47ms/step - loss: 1.8184 - accuracy: 0.3506 - val_loss: 1.6688 - val_accuracy: 0.4072
Epoch 65/150
704/704 [==============================] - 36s 51ms/step - loss: 1.8181 - accuracy: 0.3500 - val_loss: 1.6796 - val_accuracy: 0.4076

Epoch 00065: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.
