epoch,accuracy,loss,val_accuracy,val_loss
0,0.1571333259344101,2.620525598526001,0.3792000114917755,1.8667603731155396
1,0.24860000610351562,2.170682668685913,0.43380001187324524,1.7049726247787476
2,0.3021777868270874,1.972594141960144,0.46160000562667847,1.5928137302398682
3,0.3425999879837036,1.8418222665786743,0.4909999966621399,1.5039244890213013
4,0.378888875246048,1.7409496307373047,0.5058000087738037,1.4580399990081787
5,0.4017777740955353,1.6906850337982178,0.5242000222206116,1.4156168699264526
6,0.4266444444656372,1.630595088005066,0.5396000146865845,1.3700592517852783
7,0.44786667823791504,1.5850133895874023,0.5361999869346619,1.3683722019195557
8,0.4582666754722595,1.5554218292236328,0.5392000079154968,1.344157338142395
9,0.4735333323478699,1.5211595296859741,0.5490000247955322,1.325533151626587
10,0.4836222231388092,1.503183364868164,0.5608000159263611,1.2760016918182373
11,0.496444433927536,1.4669630527496338,0.5690000057220459,1.2725380659103394
12,0.504111111164093,1.4604767560958862,0.5685999989509583,1.2616709470748901
13,0.5086666941642761,1.4385751485824585,0.5702000260353088,1.262519359588623
14,0.5204222202301025,1.417487382888794,0.5906000137329102,1.2268937826156616
15,0.5267333388328552,1.4087858200073242,0.5849999785423279,1.2198446989059448
16,0.5338888764381409,1.3934175968170166,0.5756000280380249,1.2358847856521606
17,0.5324222445487976,1.3931760787963867,0.5848000049591064,1.2250550985336304
18,0.5349110960960388,1.3793834447860718,0.5860000252723694,1.212904691696167
19,0.5445111393928528,1.3622514009475708,0.5960000157356262,1.2119413614273071
20,0.5473111271858215,1.3524357080459595,0.5896000266075134,1.2042382955551147
21,0.5488888621330261,1.3538684844970703,0.5820000171661377,1.207411527633667
22,0.5516444444656372,1.3413892984390259,0.5881999731063843,1.1911534070968628
23,0.554444432258606,1.329185128211975,0.5938000082969666,1.1885395050048828
24,0.5591333508491516,1.3237088918685913,0.5982000231742859,1.1744483709335327
25,0.560533344745636,1.317226767539978,0.604200005531311,1.1651595830917358
26,0.5662888884544373,1.3062251806259155,0.5907999873161316,1.1764771938323975
27,0.5675333142280579,1.2945716381072998,0.6043999791145325,1.1625449657440186
28,0.5706889033317566,1.3020479679107666,0.593999981880188,1.171168565750122
29,0.5691333413124084,1.2958300113677979,0.6122000217437744,1.1616671085357666
30,0.5779333114624023,1.280539631843567,0.5985999703407288,1.17006254196167
31,0.5762222409248352,1.2753113508224487,0.59579998254776,1.162352442741394
32,0.5828889012336731,1.2656461000442505,0.6018000245094299,1.1651273965835571
33,0.5835333466529846,1.2640095949172974,0.604200005531311,1.153225302696228
34,0.5797111392021179,1.2711361646652222,0.6097999811172485,1.1380572319030762
35,0.5880222320556641,1.2485384941101074,0.6001999974250793,1.1596590280532837
36,0.5854889154434204,1.2497745752334595,0.6046000123023987,1.1498323678970337
37,0.5924000144004822,1.235599160194397,0.6119999885559082,1.1406577825546265
38,0.5929999947547913,1.2320679426193237,0.6176000237464905,1.1323219537734985
39,0.5920666456222534,1.2306753396987915,0.6074000000953674,1.1412330865859985
40,0.5954222083091736,1.228270173072815,0.6025999784469604,1.1399242877960205
41,0.5935778021812439,1.2266349792480469,0.5974000096321106,1.1618530750274658
42,0.5968444347381592,1.2198083400726318,0.6118000149726868,1.1306511163711548
43,0.5987333059310913,1.2158550024032593,0.6100000143051147,1.1300207376480103
44,0.6012222170829773,1.2075186967849731,0.609000027179718,1.1375069618225098
45,0.6033999919891357,1.2079507112503052,0.6074000000953674,1.127979040145874
46,0.6038888692855835,1.2031700611114502,0.6096000075340271,1.1344307661056519
47,0.6045555472373962,1.1964162588119507,0.6215999722480774,1.1259222030639648
48,0.6100666522979736,1.1884450912475586,0.6093999743461609,1.1348962783813477
49,0.6056444644927979,1.1905654668807983,0.6195999979972839,1.1194530725479126
50,0.6087999939918518,1.187937617301941,0.6164000034332275,1.1156010627746582
51,0.6122444272041321,1.1777757406234741,0.6137999892234802,1.1221579313278198
52,0.6126000285148621,1.184949517250061,0.6129999756813049,1.1409504413604736
53,0.6117555499076843,1.1800200939178467,0.620199978351593,1.11580228805542
54,0.6136000156402588,1.1712703704833984,0.6136000156402588,1.1408779621124268
55,0.6156222224235535,1.1710879802703857,0.6215999722480774,1.1201832294464111
56,0.6186444163322449,1.1571673154830933,0.6128000020980835,1.116073727607727
57,0.6217111349105835,1.1511708498001099,0.6123999953269958,1.1292635202407837
58,0.624822199344635,1.1372045278549194,0.6179999709129333,1.1072306632995605
59,0.6250222325325012,1.1462576389312744,0.6176000237464905,1.1131616830825806
60,0.6272888779640198,1.1394973993301392,0.6186000108718872,1.1150158643722534
61,0.6241333484649658,1.1473404169082642,0.6204000115394592,1.1105360984802246
62,0.6288889050483704,1.135047197341919,0.6154000163078308,1.1158260107040405
63,0.6260889172554016,1.1387085914611816,0.621999979019165,1.1125603914260864
64,0.6282666921615601,1.1338335275650024,0.6233999729156494,1.101200819015503
65,0.6265777945518494,1.1324766874313354,0.6302000284194946,1.0976264476776123
66,0.6316666603088379,1.1277642250061035,0.6209999918937683,1.1130211353302002
67,0.6272000074386597,1.1294749975204468,0.6259999871253967,1.100524663925171
68,0.6291777491569519,1.1283811330795288,0.6251999735832214,1.0946311950683594
69,0.6286444664001465,1.1352063417434692,0.618399977684021,1.1215633153915405
70,0.6303777694702148,1.1309051513671875,0.6330000162124634,1.0863606929779053
71,0.6290000081062317,1.1269513368606567,0.6140000224113464,1.1089394092559814
72,0.6320444345474243,1.1277881860733032,0.6169999837875366,1.1121389865875244
73,0.6335999965667725,1.1271940469741821,0.6245999932289124,1.1049624681472778
74,0.6285777688026428,1.126103401184082,0.621999979019165,1.0927034616470337
75,0.6302000284194946,1.1320679187774658,0.621399998664856,1.1071141958236694
76,0.6306666731834412,1.1229710578918457,0.6269999742507935,1.0946190357208252
77,0.6266666650772095,1.134748101234436,0.6150000095367432,1.1158398389816284
78,0.6304222345352173,1.125014066696167,0.6164000034332275,1.1087449789047241
79,0.6291333436965942,1.133545160293579,0.6262000203132629,1.1046825647354126
80,0.6309999823570251,1.1269769668579102,0.6320000290870667,1.0840109586715698
81,0.6300666928291321,1.1312836408615112,0.6182000041007996,1.1079052686691284
82,0.629622220993042,1.1300185918807983,0.6237999796867371,1.0914276838302612
83,0.6333555579185486,1.1300930976867676,0.620199978351593,1.1095439195632935
84,0.6311333179473877,1.1254501342773438,0.6129999756813049,1.113654613494873
85,0.631600022315979,1.1232935190200806,0.6326000094413757,1.0959194898605347
86,0.6294888854026794,1.1331661939620972,0.6195999979972839,1.1092967987060547
87,0.6353999972343445,1.1236138343811035,0.6240000128746033,1.0952837467193604
88,0.6302888989448547,1.126326084136963,0.6263999938964844,1.0905667543411255
89,0.6298888921737671,1.1278043985366821,0.6132000088691711,1.1099872589111328
90,0.6288666725158691,1.130411148071289,0.629800021648407,1.0805456638336182
91,0.6284000277519226,1.1218491792678833,0.631600022315979,1.0774463415145874
92,0.6302888989448547,1.1309022903442383,0.6255999803543091,1.104802131652832
93,0.6304000020027161,1.1259342432022095,0.6122000217437744,1.1084280014038086
94,0.630911111831665,1.1255613565444946,0.6223999857902527,1.1019824743270874
95,0.6245555281639099,1.1330589056015015,0.6236000061035156,1.1119275093078613
96,0.6313999891281128,1.126696228981018,0.6191999912261963,1.111449122428894
97,0.6255555748939514,1.141148328781128,0.6158000230789185,1.112259030342102
98,0.6323555707931519,1.1264253854751587,0.6262000203132629,1.0907652378082275
99,0.6324666738510132,1.1237671375274658,0.6326000094413757,1.0896062850952148
100,0.6272444725036621,1.1309176683425903,0.6195999979972839,1.0954461097717285
101,0.6306666731834412,1.1191003322601318,0.6197999715805054,1.1113321781158447
102,0.6310222148895264,1.1253927946090698,0.6236000061035156,1.0995219945907593
103,0.6334888935089111,1.1261520385742188,0.6209999918937683,1.106299877166748
104,0.6351110935211182,1.1248233318328857,0.6168000102043152,1.1132644414901733
105,0.632111132144928,1.1223176717758179,0.6233999729156494,1.1110303401947021
106,0.6304888725280762,1.1262041330337524,0.6273999810218811,1.10361909866333
107,0.6308666467666626,1.1304402351379395,0.6277999877929688,1.0992515087127686
108,0.6298444271087646,1.1318002939224243,0.6133999824523926,1.1115288734436035
109,0.6307333111763,1.1295348405838013,0.6313999891281128,1.0820525884628296
110,0.6312666535377502,1.1282641887664795,0.6144000291824341,1.113602876663208
111,0.6315333247184753,1.1226214170455933,0.6236000061035156,1.1129484176635742
112,0.6293333172798157,1.1298718452453613,0.6244000196456909,1.1030412912368774
113,0.6322888731956482,1.1303083896636963,0.626800000667572,1.0919768810272217
114,0.630466639995575,1.1286262273788452,0.6244000196456909,1.1019867658615112
115,0.6296666860580444,1.1298716068267822,0.6245999932289124,1.0967737436294556
116,0.632888913154602,1.1191023588180542,0.6236000061035156,1.0931637287139893

Epoch 1/150
704/704 [==============================] - 38s 49ms/step - loss: 2.8331 - accuracy: 0.1322 - val_loss: 1.8668 - val_accuracy: 0.3792
Epoch 2/150
704/704 [==============================] - 31s 44ms/step - loss: 2.2377 - accuracy: 0.2327 - val_loss: 1.7050 - val_accuracy: 0.4338
Epoch 3/150
704/704 [==============================] - 33s 47ms/step - loss: 2.0155 - accuracy: 0.2905 - val_loss: 1.5928 - val_accuracy: 0.4616
Epoch 4/150
704/704 [==============================] - 31s 44ms/step - loss: 1.8632 - accuracy: 0.3367 - val_loss: 1.5039 - val_accuracy: 0.4910
Epoch 5/150
704/704 [==============================] - 34s 48ms/step - loss: 1.7615 - accuracy: 0.3717 - val_loss: 1.4580 - val_accuracy: 0.5058
Epoch 6/150
704/704 [==============================] - 33s 47ms/step - loss: 1.7057 - accuracy: 0.3943 - val_loss: 1.4156 - val_accuracy: 0.5242
Epoch 7/150
704/704 [==============================] - 31s 44ms/step - loss: 1.6413 - accuracy: 0.4223 - val_loss: 1.3701 - val_accuracy: 0.5396
Epoch 8/150
704/704 [==============================] - 33s 47ms/step - loss: 1.5938 - accuracy: 0.4440 - val_loss: 1.3684 - val_accuracy: 0.5362
Epoch 9/150
704/704 [==============================] - 31s 44ms/step - loss: 1.5619 - accuracy: 0.4535 - val_loss: 1.3442 - val_accuracy: 0.5392
Epoch 10/150
704/704 [==============================] - 33s 47ms/step - loss: 1.5223 - accuracy: 0.4737 - val_loss: 1.3255 - val_accuracy: 0.5490
Epoch 11/150
704/704 [==============================] - 31s 43ms/step - loss: 1.5130 - accuracy: 0.4800 - val_loss: 1.2760 - val_accuracy: 0.5608
Epoch 12/150
704/704 [==============================] - 33s 47ms/step - loss: 1.4611 - accuracy: 0.4954 - val_loss: 1.2725 - val_accuracy: 0.5690
Epoch 13/150
704/704 [==============================] - 31s 44ms/step - loss: 1.4483 - accuracy: 0.5093 - val_loss: 1.2617 - val_accuracy: 0.5686
Epoch 14/150
704/704 [==============================] - 33s 47ms/step - loss: 1.4453 - accuracy: 0.5057 - val_loss: 1.2625 - val_accuracy: 0.5702
Epoch 15/150
704/704 [==============================] - 33s 47ms/step - loss: 1.4205 - accuracy: 0.5210 - val_loss: 1.2269 - val_accuracy: 0.5906
Epoch 16/150
704/704 [==============================] - 34s 49ms/step - loss: 1.4036 - accuracy: 0.5272 - val_loss: 1.2198 - val_accuracy: 0.5850
Epoch 17/150
704/704 [==============================] - 34s 49ms/step - loss: 1.3989 - accuracy: 0.5303 - val_loss: 1.2359 - val_accuracy: 0.5756
Epoch 18/150
704/704 [==============================] - 31s 44ms/step - loss: 1.3937 - accuracy: 0.5313 - val_loss: 1.2251 - val_accuracy: 0.5848
Epoch 19/150
704/704 [==============================] - 33s 46ms/step - loss: 1.3821 - accuracy: 0.5327 - val_loss: 1.2129 - val_accuracy: 0.5860
Epoch 20/150
704/704 [==============================] - 31s 44ms/step - loss: 1.3710 - accuracy: 0.5408 - val_loss: 1.2119 - val_accuracy: 0.5960
Epoch 21/150
704/704 [==============================] - 33s 47ms/step - loss: 1.3523 - accuracy: 0.5487 - val_loss: 1.2042 - val_accuracy: 0.5896
Epoch 22/150
704/704 [==============================] - 31s 45ms/step - loss: 1.3403 - accuracy: 0.5519 - val_loss: 1.2074 - val_accuracy: 0.5820
Epoch 23/150
704/704 [==============================] - 32s 45ms/step - loss: 1.3448 - accuracy: 0.5517 - val_loss: 1.1912 - val_accuracy: 0.5882
Epoch 24/150
704/704 [==============================] - 32s 45ms/step - loss: 1.3214 - accuracy: 0.5552 - val_loss: 1.1885 - val_accuracy: 0.5938
Epoch 25/150
704/704 [==============================] - 32s 45ms/step - loss: 1.3230 - accuracy: 0.5578 - val_loss: 1.1744 - val_accuracy: 0.5982
Epoch 26/150
704/704 [==============================] - 33s 47ms/step - loss: 1.3134 - accuracy: 0.5596 - val_loss: 1.1652 - val_accuracy: 0.6042
Epoch 27/150
704/704 [==============================] - 32s 45ms/step - loss: 1.2977 - accuracy: 0.5702 - val_loss: 1.1765 - val_accuracy: 0.5908
Epoch 28/150
704/704 [==============================] - 32s 45ms/step - loss: 1.2997 - accuracy: 0.5671 - val_loss: 1.1625 - val_accuracy: 0.6044
Epoch 29/150
704/704 [==============================] - 33s 46ms/step - loss: 1.2873 - accuracy: 0.5752 - val_loss: 1.1712 - val_accuracy: 0.5940
Epoch 30/150
704/704 [==============================] - 32s 45ms/step - loss: 1.2932 - accuracy: 0.5700 - val_loss: 1.1617 - val_accuracy: 0.6122
Epoch 31/150
704/704 [==============================] - 32s 46ms/step - loss: 1.2673 - accuracy: 0.5833 - val_loss: 1.1701 - val_accuracy: 0.5986
Epoch 32/150
704/704 [==============================] - 31s 44ms/step - loss: 1.2707 - accuracy: 0.5771 - val_loss: 1.1624 - val_accuracy: 0.5958
Epoch 33/150
704/704 [==============================] - 33s 46ms/step - loss: 1.2601 - accuracy: 0.5838 - val_loss: 1.1651 - val_accuracy: 0.6018
Epoch 34/150
704/704 [==============================] - 31s 44ms/step - loss: 1.2663 - accuracy: 0.5821 - val_loss: 1.1532 - val_accuracy: 0.6042
Epoch 35/150
704/704 [==============================] - 33s 46ms/step - loss: 1.2669 - accuracy: 0.5818 - val_loss: 1.1381 - val_accuracy: 0.6098
Epoch 36/150
704/704 [==============================] - 30s 43ms/step - loss: 1.2409 - accuracy: 0.5897 - val_loss: 1.1597 - val_accuracy: 0.6002
Epoch 37/150
704/704 [==============================] - 33s 47ms/step - loss: 1.2558 - accuracy: 0.5835 - val_loss: 1.1498 - val_accuracy: 0.6046
Epoch 38/150
704/704 [==============================] - 33s 47ms/step - loss: 1.2373 - accuracy: 0.5910 - val_loss: 1.1407 - val_accuracy: 0.6120
Epoch 39/150
704/704 [==============================] - 31s 44ms/step - loss: 1.2303 - accuracy: 0.5963 - val_loss: 1.1323 - val_accuracy: 0.6176
Epoch 40/150
704/704 [==============================] - 34s 48ms/step - loss: 1.2214 - accuracy: 0.5953 - val_loss: 1.1412 - val_accuracy: 0.6074
Epoch 41/150
704/704 [==============================] - 31s 44ms/step - loss: 1.2259 - accuracy: 0.5948 - val_loss: 1.1399 - val_accuracy: 0.6026
Epoch 42/150
704/704 [==============================] - 34s 48ms/step - loss: 1.2283 - accuracy: 0.5933 - val_loss: 1.1619 - val_accuracy: 0.5974
Epoch 43/150
704/704 [==============================] - 31s 44ms/step - loss: 1.2168 - accuracy: 0.5977 - val_loss: 1.1307 - val_accuracy: 0.6118
Epoch 44/150
704/704 [==============================] - 34s 48ms/step - loss: 1.2088 - accuracy: 0.5999 - val_loss: 1.1300 - val_accuracy: 0.6100
Epoch 45/150
704/704 [==============================] - 30s 43ms/step - loss: 1.2051 - accuracy: 0.6023 - val_loss: 1.1375 - val_accuracy: 0.6090
Epoch 46/150
704/704 [==============================] - 33s 47ms/step - loss: 1.2094 - accuracy: 0.6030 - val_loss: 1.1280 - val_accuracy: 0.6074
Epoch 47/150
704/704 [==============================] - 33s 47ms/step - loss: 1.2025 - accuracy: 0.6036 - val_loss: 1.1344 - val_accuracy: 0.6096
Epoch 48/150
704/704 [==============================] - 30s 43ms/step - loss: 1.1831 - accuracy: 0.6116 - val_loss: 1.1259 - val_accuracy: 0.6216
Epoch 49/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1899 - accuracy: 0.6101 - val_loss: 1.1349 - val_accuracy: 0.6094
Epoch 50/150
704/704 [==============================] - 33s 46ms/step - loss: 1.1822 - accuracy: 0.6099 - val_loss: 1.1195 - val_accuracy: 0.6196
Epoch 51/150
704/704 [==============================] - 36s 51ms/step - loss: 1.1836 - accuracy: 0.6106 - val_loss: 1.1156 - val_accuracy: 0.6164
Epoch 52/150
704/704 [==============================] - 32s 46ms/step - loss: 1.1805 - accuracy: 0.6105 - val_loss: 1.1222 - val_accuracy: 0.6138
Epoch 53/150
704/704 [==============================] - 35s 49ms/step - loss: 1.1864 - accuracy: 0.6106 - val_loss: 1.1410 - val_accuracy: 0.6130
Epoch 54/150
704/704 [==============================] - 31s 44ms/step - loss: 1.1742 - accuracy: 0.6118 - val_loss: 1.1158 - val_accuracy: 0.6202
Epoch 55/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1674 - accuracy: 0.6158 - val_loss: 1.1409 - val_accuracy: 0.6136
Epoch 56/150
704/704 [==============================] - 31s 43ms/step - loss: 1.1704 - accuracy: 0.6178 - val_loss: 1.1202 - val_accuracy: 0.6216

Epoch 00056: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 57/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1672 - accuracy: 0.6189 - val_loss: 1.1161 - val_accuracy: 0.6128
Epoch 58/150
704/704 [==============================] - 35s 49ms/step - loss: 1.1517 - accuracy: 0.6236 - val_loss: 1.1293 - val_accuracy: 0.6124
Epoch 59/150
704/704 [==============================] - 30s 43ms/step - loss: 1.1371 - accuracy: 0.6233 - val_loss: 1.1072 - val_accuracy: 0.6180
Epoch 60/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1564 - accuracy: 0.6214 - val_loss: 1.1132 - val_accuracy: 0.6176
Epoch 61/150
704/704 [==============================] - 31s 44ms/step - loss: 1.1403 - accuracy: 0.6264 - val_loss: 1.1150 - val_accuracy: 0.6186
Epoch 62/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1550 - accuracy: 0.6200 - val_loss: 1.1105 - val_accuracy: 0.6204
Epoch 63/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1327 - accuracy: 0.6315 - val_loss: 1.1158 - val_accuracy: 0.6154
Epoch 64/150
704/704 [==============================] - 33s 46ms/step - loss: 1.1381 - accuracy: 0.6245 - val_loss: 1.1126 - val_accuracy: 0.6220

Epoch 00064: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 65/150
704/704 [==============================] - 31s 44ms/step - loss: 1.1323 - accuracy: 0.6298 - val_loss: 1.1012 - val_accuracy: 0.6234
Epoch 66/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1339 - accuracy: 0.6252 - val_loss: 1.0976 - val_accuracy: 0.6302
Epoch 67/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1275 - accuracy: 0.6328 - val_loss: 1.1130 - val_accuracy: 0.6210
Epoch 68/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1287 - accuracy: 0.6271 - val_loss: 1.1005 - val_accuracy: 0.6260
Epoch 69/150
704/704 [==============================] - 33s 46ms/step - loss: 1.1305 - accuracy: 0.6294 - val_loss: 1.0946 - val_accuracy: 0.6252
Epoch 70/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1366 - accuracy: 0.6274 - val_loss: 1.1216 - val_accuracy: 0.6184
Epoch 71/150
704/704 [==============================] - 33s 46ms/step - loss: 1.1238 - accuracy: 0.6306 - val_loss: 1.0864 - val_accuracy: 0.6330
Epoch 72/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1317 - accuracy: 0.6269 - val_loss: 1.1089 - val_accuracy: 0.6140
Epoch 73/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1300 - accuracy: 0.6311 - val_loss: 1.1121 - val_accuracy: 0.6170
Epoch 74/150
704/704 [==============================] - 32s 46ms/step - loss: 1.1300 - accuracy: 0.6331 - val_loss: 1.1050 - val_accuracy: 0.6246
Epoch 75/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1229 - accuracy: 0.6289 - val_loss: 1.0927 - val_accuracy: 0.6220
Epoch 76/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1312 - accuracy: 0.6305 - val_loss: 1.1071 - val_accuracy: 0.6214

Epoch 00076: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 77/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1080 - accuracy: 0.6336 - val_loss: 1.0946 - val_accuracy: 0.6270
Epoch 78/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1301 - accuracy: 0.6320 - val_loss: 1.1158 - val_accuracy: 0.6150
Epoch 79/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1267 - accuracy: 0.6299 - val_loss: 1.1087 - val_accuracy: 0.6164
Epoch 80/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1312 - accuracy: 0.6301 - val_loss: 1.1047 - val_accuracy: 0.6262
Epoch 81/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1163 - accuracy: 0.6360 - val_loss: 1.0840 - val_accuracy: 0.6320
Epoch 82/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1399 - accuracy: 0.6291 - val_loss: 1.1079 - val_accuracy: 0.6182
Epoch 83/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1336 - accuracy: 0.6308 - val_loss: 1.0914 - val_accuracy: 0.6238
Epoch 84/150
704/704 [==============================] - 35s 49ms/step - loss: 1.1192 - accuracy: 0.6407 - val_loss: 1.1095 - val_accuracy: 0.6202
Epoch 85/150
704/704 [==============================] - 33s 46ms/step - loss: 1.1318 - accuracy: 0.6286 - val_loss: 1.1137 - val_accuracy: 0.6130
Epoch 86/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1107 - accuracy: 0.6359 - val_loss: 1.0959 - val_accuracy: 0.6326

Epoch 00086: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 87/150
704/704 [==============================] - 35s 49ms/step - loss: 1.1427 - accuracy: 0.6293 - val_loss: 1.1093 - val_accuracy: 0.6196
Epoch 88/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1321 - accuracy: 0.6341 - val_loss: 1.0953 - val_accuracy: 0.6240
Epoch 89/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1283 - accuracy: 0.6300 - val_loss: 1.0906 - val_accuracy: 0.6264
Epoch 90/150
704/704 [==============================] - 32s 46ms/step - loss: 1.1306 - accuracy: 0.6285 - val_loss: 1.1100 - val_accuracy: 0.6132
Epoch 91/150
704/704 [==============================] - 35s 49ms/step - loss: 1.1305 - accuracy: 0.6283 - val_loss: 1.0805 - val_accuracy: 0.6298
Epoch 92/150
704/704 [==============================] - 32s 46ms/step - loss: 1.1170 - accuracy: 0.6302 - val_loss: 1.0774 - val_accuracy: 0.6316
Epoch 93/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1330 - accuracy: 0.6294 - val_loss: 1.1048 - val_accuracy: 0.6256
Epoch 94/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1211 - accuracy: 0.6303 - val_loss: 1.1084 - val_accuracy: 0.6122
Epoch 95/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1223 - accuracy: 0.6296 - val_loss: 1.1020 - val_accuracy: 0.6224
Epoch 96/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1318 - accuracy: 0.6244 - val_loss: 1.1119 - val_accuracy: 0.6236
Epoch 97/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1334 - accuracy: 0.6279 - val_loss: 1.1114 - val_accuracy: 0.6192

Epoch 00097: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 98/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1428 - accuracy: 0.6240 - val_loss: 1.1123 - val_accuracy: 0.6158
Epoch 99/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1344 - accuracy: 0.6280 - val_loss: 1.0908 - val_accuracy: 0.6262
Epoch 100/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1180 - accuracy: 0.6341 - val_loss: 1.0896 - val_accuracy: 0.6326
Epoch 101/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1233 - accuracy: 0.6318 - val_loss: 1.0954 - val_accuracy: 0.6196
Epoch 102/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1190 - accuracy: 0.6313 - val_loss: 1.1113 - val_accuracy: 0.6198

Epoch 00102: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.
Epoch 103/150
704/704 [==============================] - 33s 47ms/step - loss: 1.1272 - accuracy: 0.6310 - val_loss: 1.0995 - val_accuracy: 0.6236
Epoch 104/150
704/704 [==============================] - 36s 51ms/step - loss: 1.1259 - accuracy: 0.6342 - val_loss: 1.1063 - val_accuracy: 0.6210
Epoch 105/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1240 - accuracy: 0.6349 - val_loss: 1.1133 - val_accuracy: 0.6168
Epoch 106/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1211 - accuracy: 0.6335 - val_loss: 1.1110 - val_accuracy: 0.6234
Epoch 107/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1213 - accuracy: 0.6321 - val_loss: 1.1036 - val_accuracy: 0.6274

Epoch 00107: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.
Epoch 108/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1310 - accuracy: 0.6299 - val_loss: 1.0993 - val_accuracy: 0.6278
Epoch 109/150
704/704 [==============================] - 35s 49ms/step - loss: 1.1351 - accuracy: 0.6258 - val_loss: 1.1115 - val_accuracy: 0.6134
Epoch 110/150
704/704 [==============================] - 31s 45ms/step - loss: 1.1243 - accuracy: 0.6329 - val_loss: 1.0821 - val_accuracy: 0.6314
Epoch 111/150
704/704 [==============================] - 34s 48ms/step - loss: 1.1347 - accuracy: 0.6292 - val_loss: 1.1136 - val_accuracy: 0.6144
Epoch 112/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1230 - accuracy: 0.6282 - val_loss: 1.1129 - val_accuracy: 0.6236

Epoch 00112: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.
Epoch 113/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1338 - accuracy: 0.6282 - val_loss: 1.1030 - val_accuracy: 0.6244
Epoch 114/150
704/704 [==============================] - 32s 46ms/step - loss: 1.1287 - accuracy: 0.6321 - val_loss: 1.0920 - val_accuracy: 0.6268
Epoch 115/150
704/704 [==============================] - 35s 50ms/step - loss: 1.1279 - accuracy: 0.6301 - val_loss: 1.1020 - val_accuracy: 0.6244
Epoch 116/150
704/704 [==============================] - 34s 49ms/step - loss: 1.1282 - accuracy: 0.6308 - val_loss: 1.0968 - val_accuracy: 0.6246
Epoch 117/150
704/704 [==============================] - 32s 45ms/step - loss: 1.1200 - accuracy: 0.6309 - val_loss: 1.0932 - val_accuracy: 0.6236

Epoch 00117: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.
